# main.py
# 0924 ë³€ê²½:
# 1. ì‹¤ìˆ˜ë¡œ ìƒëµë˜ì—ˆë˜ is_safety_text ë° kiwi í™œìš© ë¡œì§ì„ ì™„ë²½í•˜ê²Œ ë³µì›.
# 2. Checkin ëª¨ë¸ì—ì„œ contexts ì œê±°.
# 3. í™ˆì—ì„œ ì„ íƒí•œ ì´ëª¨ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¡œì§ ì¶”ê°€.
# 4. ìˆ˜ì¹˜ ì ìˆ˜ë¥¼ ì‚¬ìš©ì ì¹œí™”ì  ë¬¸êµ¬ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€.
# 5. ì†”ë£¨ì…˜ ì œì•ˆ ì‹œ, ì œì•ˆ ë©˜íŠ¸ì™€ ì†”ë£¨ì…˜ ìƒì„¸ ì •ë³´ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •.
# 6. Supabase ì €ì¥ ë¡œì§ ê°•í™” (ë¦¬í¬íŠ¸ë¥¼ ìœ„í•œ cluster_scores ì €ì¥).

from __future__ import annotations

import datetime as dt
import json
import os
import re
import traceback
import random
from typing import Optional, List, Dict, Any, Tuple

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from supabase import create_client

from llm_prompts import call_llm, TRIAGE_SYSTEM_PROMPT, ANALYSIS_SYSTEM_PROMPT, FRIENDLY_SYSTEM_PROMPT
from rule_based import rule_scoring
from srj5_constants import (
    CLUSTERS, DSM_BETA, META_WEIGHTS, ONBOARDING_MAPPING,
    W_LLM, W_RULE, SOLUTION_ID_LIBRARY, ANALYSIS_MESSAGE_LIBRARY, SOLUTION_PROPOSAL_SCRIPTS,
    SAFETY_LEMMAS, SAFETY_LEMMA_COMBOS, PCA_PROXY
)


try:
    from kiwipiepy import Kiwi
    _kiwi = Kiwi()
except Exception:
    _kiwi = None

# --- í™˜ê²½ì„¤ì • ---
load_dotenv()
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
BIND_HOST = os.getenv("BIND_HOST", "0.0.0.0")
PORT = int(os.getenv("PORT", "8000"))
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None

# --- FastAPI ì•± ì´ˆê¸°í™” ---
app = FastAPI(title="DailyMoji API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"],
)

# --- ë°ì´í„° ëª¨ë¸ ---
class Checkin(BaseModel):
    user_id: str
    text: str
    icon: Optional[str] = None
    timestamp: Optional[str] = None
    onboarding: Optional[Dict[str, Any]] = None
    action: Optional[Dict[str, Any]] = None

# ======================================================================
# === kiwië¥¼ ì‚¬ìš©í•˜ëŠ” ì•ˆì „ ì¥ì¹˜ ë° Helper í•¨ìˆ˜ë“¤ ===
# ======================================================================

# --- ì•ˆì „ ì¥ì¹˜ ë¡œì§ ---
SAFETY_REGEX = [r"ì£½ê³ \s*ì‹¶", r"ì‚´ê³ \s*ì‹¶ì§€", r"ì‚´ê¸°\s*ì‹«", r"ìì‚´", r"ë›°ì–´\s*ë‚´ë¦¬", r"íˆ¬ì‹ ", r"ëª©ì„\s*ë§¤ë‹¬", r"ëª©ìˆ¨(?:ì„)?\s*ëŠ", r"ìƒì„\s*ë§ˆê°", r"ì£½ì–´ë²„ë¦¬", r"ëë‚´ë²„ë¦¬"]
SAFETY_FIGURATIVE = [r"ì£½ì„\s*ë§Œí¼", r"ì£½ê² ë‹¤\s*ã…‹", r"ê°œ\s*ë§›ìˆ"]

def _find_regex_matches(text: str, patterns: List[str]) -> List[str]:
    return [m.group(0) for pat in patterns for m in re.finditer(pat, text, flags=re.IGNORECASE)]

def _kiwi_detect_safety_lemmas(text: str) -> List[str]:
    if not _kiwi: return []
    try:
        tokens = _kiwi.tokenize(text)
        all_lemmas_in_text = {t.lemma for t in tokens}
        hits = {token.lemma for token in tokens if token.lemma in SAFETY_LEMMAS}
        for combo in SAFETY_LEMMA_COMBOS:
            if combo.issubset(all_lemmas_in_text):
                hits.update(combo)
        return list(hits)
    except Exception as e:
        print(f"Kiwi safety check error: {e}")
        return []

def is_safety_text(text: str, llm_json: Optional[dict], debug_log: dict) -> Tuple[bool, dict]:
    kiwi_lemma_hits = _kiwi_detect_safety_lemmas(text)
    safety_llm_flag = (llm_json or {}).get("intent", {}).get("self_harm") in {"possible", "likely"}
    
    # ì€ìœ ì ì´ê±°ë‚˜ ë†ë‹´ í‘œí˜„ì´ ì—†ì„ ë•Œë§Œ ì•ˆì „ ì¥ì¹˜ë¥¼ ë°œë™
    is_figurative = bool(_find_regex_matches(text, SAFETY_FIGURATIVE))
    triggered = (bool(kiwi_lemma_hits) or safety_llm_flag) and not is_figurative
    
    debug_log["safety"] = {
        "regex_matches": _find_regex_matches(text, SAFETY_REGEX),
        "figurative_matches": _find_regex_matches(text, SAFETY_FIGURATIVE),
        "kiwi_lemma_hits": kiwi_lemma_hits,
        "llm_intent_flag": safety_llm_flag,
        "triggered": triggered
    }
    
    if triggered:
        # ì•ˆì „ ì¥ì¹˜ê°€ ë°œë™í•˜ë©´, neg_low ì ìˆ˜ë¥¼ ê·¹ë‹¨ì ìœ¼ë¡œ ë†’ì—¬ ìœ„ê¸° ìƒí™©ì„ì„ ëª…ì‹œ
        return True, {"neg_low": 0.95, "neg_high": 0.0, "adhd_high": 0.0, "sleep": 0.0, "positive": 0.0}
    
    return False, {}


# --- Helper í•¨ìˆ˜ë“¤ ---
def clip01(x: float) -> float: return max(0.0, min(1.0, float(x)))

def _is_night(ts: Optional[str]) -> bool:
    try:
        if not ts: return False
        hour = dt.datetime.fromisoformat(ts.replace("Z", "+00:00")).hour
        return hour >= 22 or hour < 7
    except Exception: return False

def g_score(final_scores: dict) -> float:
    w = {"neg_high": 1.0, "neg_low": 0.9, "sleep": 0.7, "adhd_high": 0.6, "positive": -0.3}
    g = sum(final_scores.get(k, 0.0) * w.get(k, 0.0) for k in CLUSTERS)
    return round(clip01((g + 1.0) / 2.0), 3)

def calculate_baseline_scores(onboarding_scores: Dict[str, int]) -> Dict[str, float]:
    if not onboarding_scores: return {c: 0.0 for c in CLUSTERS} # ì˜¨ë³´ë”© ìŠ¤ì½”ì–´ê°€ ì—†ìœ¼ë©´ ëª¨ë‘ 0ìœ¼ë¡œ ì´ˆê¸°í™”
    baseline = {c: 0.0 for c in CLUSTERS}
    for q_key, score in onboarding_scores.items():
        processed_score = 3 - score if q_key == 'q7' else score
        if q_key in ONBOARDING_MAPPING:
            normalized_score = processed_score / 3.0
            for mapping in ONBOARDING_MAPPING[q_key]:
                baseline[mapping["cluster"]] += normalized_score * mapping["w"]
    for c in CLUSTERS:
        baseline[c] = clip01(baseline[c]) if c == 'positive' else max(-1.0, min(1.0, baseline[c]))
    return baseline


def meta_adjust(base_scores: dict, payload: Checkin) -> dict:
    s = base_scores.copy()

    # ì´ëª¨ì§€ ì•„ì´ì½˜ ì ìˆ˜ ê°€ì¤‘ì¹˜ 
    if payload.icon and payload.icon.lower() in CLUSTERS:
        # ì´ëª¨ì§€ ì„ íƒ ì‹œ 70%, ì˜¨ë³´ë”© 30%ë¥¼ ë°±ì—”ë“œì—ì„œ ê²°í•©
        # ì—¬ê¸°ì„œ base_scoresëŠ” ì´ë¯¸ LLMê³¼ Rule ê¸°ë°˜ ì ìˆ˜ê°€ ìœµí•©ëœ ìƒíƒœ.
        # ê¸°ì¡´ ì ìˆ˜(LLM+Rule)ì— ì´ëª¨ì§€ ì ìˆ˜ë¥¼ 'ì¶”ê°€'í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹Œ,
        # 'ì¬ê³„ì‚°' ë˜ëŠ” 'ê°•ë ¥í•œ ë³´ì •' ê°œë…ìœ¼ë¡œ ì ‘ê·¼.
        # -> ë°±ì—”ë“œì—ì„œ icon íŒŒë¼ë¯¸í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œ, í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬.

        # í´ëŸ¬ìŠ¤í„° ë§¤í•‘ (ì´ëª¨ì§€ íŒŒì¼ëª…ê³¼ ë°±ì—”ë“œ í´ëŸ¬ìŠ¤í„° ë§¤í•‘)
        icon_to_cluster = {
            "angry": "neg_high",
            "crying": "neg_low",
            "shocked": "adhd_high",
            "sleeping": "sleep",
            "smile": "positive",
        }
        
        selected_cluster = icon_to_cluster.get(payload.icon.lower())
        if selected_cluster:
            # ì„ íƒëœ ì´ëª¨ì§€ í´ëŸ¬ìŠ¤í„°ì— 70% ê°€ì¤‘ì¹˜ (ê¸°ì¡´ ì ìˆ˜ì™€ í•©ì‚°)
            s[selected_cluster] = clip01(s[selected_cluster] + 0.7) 
            # ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì¶¤ (í˜¹ì€ ë³€í™” ì—†ìŒ)
            
    # if any(ctx in ["night", "ë°¤"] for ctx in (payload.contexts or [])) or _is_night(payload.timestamp):
    if _is_night(payload.timestamp): # contexts í•„ë“œ ì œê±°
        s["sleep"] = clip01(s["sleep"] + META_WEIGHTS["time"] * 0.2)
    return s



def dsm_calibrate(scores: dict) -> dict:
    # í˜„ì¬ëŠ” survey ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ë¹„í™œì„±í™”
    return scores

def pick_profile(final_scores: dict, llm: dict | None) -> int: # surveys íŒŒë¼ë¯¸í„° ì œê±°
    if (llm or {}).get("intent", {}).get("self_harm") in {"possible", "likely"}: return 1
    if max(final_scores.get("neg_low", 0), final_scores.get("neg_high", 0)) > 0.85: return 1
    # if (surveys and (surveys.get("phq9", 0) >= 10 or surveys.get("gad7", 0) >= 10)) or max(final_scores.values()) > 0.60: return 2
    if max(final_scores.values()) > 0.60: return 2 # surveys í•„ë“œ ì œê±°
    if max(final_scores.values()) > 0.30: return 3
    return 0

def pca_proxy(final_scores: dict) -> dict:
    pc1 = sum(final_scores.get(k, 0.0) * w for k, w in PCA_PROXY["pc1"].items())
    pc2 = sum(final_scores.get(k, 0.0) * w for k, w in PCA_PROXY["pc2"].items())
    return {"pc1": round(max(-1.0, min(1.0, pc1)), 3), "pc2": round(clip01((pc2 + 1.0) / 2.0), 3)}

async def generate_friendly_reply(text: str) -> str:
    llm_response = await call_llm(system_prompt=FRIENDLY_SYSTEM_PROMPT, user_content=text, openai_key=OPENAI_KEY, model="gpt-4o-mini", temperature=0.7, expect_json=False)
    return str(llm_response).strip()


# ìˆ˜ì¹˜ë¥¼ ì£¼ê¸°ë³´ë‹¤ëŠ”, ì‹¬ê°ë„ 3ë‹¨ê³„ì— ë”°ë¼ ë©”ì‹œì§€ í•´ì„í•´ì£¼ëŠ”ê²Œ ë‹¬ë¼ì§
def get_analysis_message(scores: dict) -> str:
    if not scores: return "ë‹¹ì‹ ì˜ ë§ˆìŒì„ ë” ë“¤ì—¬ë‹¤ë³´ê³  ìˆì–´ìš”."
    top_cluster = max(scores, key=scores.get)
    score_val = scores[top_cluster]
    
    level = "low"
    if score_val > 0.7: level = "high"
    elif score_val > 0.4: level = "mid"
    
    return ANALYSIS_MESSAGE_LIBRARY.get(top_cluster, {}).get(level, "ì˜¤ëŠ˜ ë‹¹ì‹ ì˜ ë§ˆìŒì€ íŠ¹ë³„í•œ ìƒ‰ì„ ë ê³  ìˆë„¤ìš”.")


async def get_solution_proposal(top_cluster: str) -> Dict[str, Any]:
    proposal_script = random.choice(SOLUTION_PROPOSAL_SCRIPTS.get(top_cluster, [""]))
    solution_id = random.choice(SOLUTION_ID_LIBRARY.get(top_cluster, [None]))
    
    if not solution_id:
        return {"proposal_text": "ì§€ê¸ˆì€ ì œì•ˆí•´ë“œë¦´ë§Œí•œ íŠ¹ë³„í•œ í™œë™ì´ ì—†ë„¤ìš”. ëŒ€ì‹ , í¸ì•ˆí•˜ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆê¹Œìš”?", "solution_id": None, "solution_data": None}

    solution_data = None
    if supabase and solution_id:
        try:
            # SupabaseëŠ” ë¹„ë™ê¸° í˜¸ì¶œì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ë„¤..
            response = supabase.table("solutions").select("*").eq("solution_id", solution_id).maybe_single().execute()
            solution_data = response.data
        except Exception as e:
            print(f"Supabase solution fetch error: {e}")

    final_text = proposal_script
    if solution_data and solution_data.get('text'):
        final_text += solution_data.get('text')
        
    return {"proposal_text": final_text, "solution_id": solution_id, "solution_data": solution_data}



async def save_to_supabase(payload: Checkin, profile: int, g: float, intervention: dict, debug_log: dict, final_scores: dict) -> Optional[str]:
    if not supabase: return None
    try:
        session_row = { "user_id": payload.user_id, "text": payload.text, "profile": profile, "g_score": g, "intervention": json.dumps(intervention, ensure_ascii=False), "debug_log": json.dumps(debug_log, ensure_ascii=False), "icon": payload.icon }
        response = supabase.table("sessions").insert(session_row).execute()
        new_session_id = response.data[0]['id']

        if final_scores:
            score_rows = [{"session_id": new_session_id, "user_id": payload.user_id, "cluster": c, "score": v} for c, v in final_scores.items()]
            if score_rows:
                supabase.table("cluster_scores").insert(score_rows).execute()
        
        return new_session_id
    except Exception as e:
        print(f"Supabase ì €ì¥ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None

# ---------- API Endpoint ----------
@app.post("/checkin")
async def checkin(payload: Checkin):
    text = (payload.text or "").strip()
    debug_log: Dict[str, Any] = {"input": payload.dict()}
    try:
        # --- íŒŒì´í”„ë¼ì¸ 0: ì‚¬ì „ ì²˜ë¦¬ (ì†”ë£¨ì…˜ ìˆ˜ë½ ë“±) ---
        if payload.action and payload.action.get("type") == "accept_solution":
            return {"intervention": {"preset_id": "SOLUTION_PROVIDED", "solution_id": payload.action.get("solution_id")}}

        # --- íŠ¹ë³„ ì¼€ì´ìŠ¤: í™ˆì—ì„œ ì´ëª¨ì§€ë§Œ ì„ íƒí•˜ê³  ë“¤ì–´ì˜¨ ê²½ìš° ---
        if payload.icon and not payload.text:
            debug_log["mode"] = "EMOJI_ONLY_ANALYSIS"
            baseline_scores = calculate_baseline_scores(payload.onboarding)
            
            final_scores = {c: baseline_scores.get(c, 0.0) * 0.3 for c in CLUSTERS}
            emoji_cluster_map = {
                "angry": "neg_high", "crying": "neg_low", "shocked": "adhd_high",
                "sleeping": "sleep", "smile": "positive"
            }
            emoji_cluster = emoji_cluster_map.get(payload.icon)
            if emoji_cluster:
                final_scores[emoji_cluster] = final_scores.get(emoji_cluster, 0.0) + 0.7
            
            final_scores = {c: clip01(v) for c, v in final_scores.items()}
            
            g = g_score(final_scores)
            profile = pick_profile(final_scores, None)
            analysis_text = get_analysis_message(final_scores)
            top_cluster = max(final_scores, key=final_scores.get, default="neg_low")
            solution_info = await get_solution_proposal(top_cluster)
            
            intervention = { "preset_id": "SOLUTION_PROPOSAL", "analysis_text": analysis_text, **solution_info }
            
            session_id = await save_to_supabase(payload, profile, g, intervention, debug_log, final_scores)
            return {"session_id": session_id, "final_scores": final_scores, "g_score": g, "profile": profile, "intervention": intervention, "debug_log": debug_log}



# ======================================================================
# ===          ì¼ë°˜ ì±„íŒ… í”Œë¡œìš°         ===
# ======================================================================
        text = (payload.text or "").strip()

        # --- íŒŒì´í”„ë¼ì¸ 1: 1ì°¨ ì•ˆì „ ì¥ì¹˜ (LLM ì—†ì´) ---
        is_safe, final_scores = is_safety_text(text, None, debug_log)
        if is_safe:
            print(f"ğŸš¨ 1ì°¨ ì•ˆì „ ì¥ì¹˜ ë°œë™: '{text}'")
            profile, g = 1, g_score(final_scores)
            dominant_neg_cluster = "neg_low" if final_scores.get("neg_low", 0) >= final_scores.get("neg_high", 0) else "neg_high"
            intervention = {"preset_id": "SAFETY_CRISIS_MODAL", "cluster": dominant_neg_cluster, "solution_id": f"{dominant_neg_cluster}_crisis_01"}
            new_session_id = save_to_supabase(payload, text, profile, g, intervention, debug_log, final_scores)
            return {"session_id": new_session_id, "input": payload.dict(), "final_scores": final_scores, "g_score": g, "profile": profile, "intervention": intervention, "debug_log": debug_log}

        # --- íŒŒì´í”„ë¼ì¸ 2: Triage (ì¹œêµ¬ ëª¨ë“œ / ë¶„ì„ ëª¨ë“œ ë¶„ê¸°) ---
        # í™ˆì—ì„œ ì´ëª¨ì§€ ëˆŒë €ì„ ë•Œ 70% ì ìˆ˜, ì˜¨ë³´ë”© 30% ì ìˆ˜ ê²°í•©í•˜ì—¬ ìŠ¤ì½”ì–´ë§.
        # -> ì´ê²ƒì€ ë°±ì—”ë“œ analyzeEmotion ë¡œì§ì—ì„œ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨.
        # -> ì¼ë‹¨ Triage ë‹¨ê³„ì—ì„œëŠ” í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“œë¥¼ ê²°ì •.
        rule_scores, _, _ = rule_scoring(text)
        max_rule_score = max(rule_scores.values() or [0.0])
        chosen_mode = "FRIENDLY"
        if max_rule_score >= 0.3 or len(text) >= 10:
            chosen_mode = "ANALYSIS"
        
        if chosen_mode == "FRIENDLY":
            debug_log["mode"] = "FRIENDLY_REPLY"
            friendly_text = await generate_friendly_reply(text)
            intervention = {"preset_id": "FRIENDLY_REPLY", "text": friendly_text}
            session_id = await save_to_supabase(payload, 0, 0.0, intervention, debug_log, {})
            return {"session_id": session_id, "intervention": intervention}

        # --- íŒŒì´í”„ë¼ì¸ 3: ë¶„ì„ ëª¨ë“œ ---
        debug_log["mode"] = "ANALYSIS"
        llm_payload = payload.dict()
        llm_payload["baseline_scores"] = calculate_baseline_scores(payload.onboarding or {})
        llm_json = await call_llm(system_prompt=ANALYSIS_SYSTEM_PROMPT, user_content=json.dumps(llm_payload, ensure_ascii=False), openai_key=OPENAI_KEY)
        debug_log["llm"] = llm_json
        
        # --- íŒŒì´í”„ë¼ì¸ 3.5: 2ì°¨ ì•ˆì „ ì¥ì¹˜ (LLM ê²°ê³¼ ê¸°ë°˜) ---
        is_safe_llm, crisis_scores_llm = is_safety_text(text, llm_json, debug_log)
        if is_safe_llm:
            print("ğŸš¨ 2ì°¨ ì•ˆì „ ì¥ì¹˜ ë°œë™ (LLM ê¸°ë°˜)")
            profile, g = 1, g_score(crisis_scores_llm)
            harm_intent = (llm_json or {}).get("intent", {}).get("self_harm", "none")
            preset = "SAFETY_CRISIS_SELF_HARM" if harm_intent == 'likely' else "SAFETY_CHECK_IN"
            intervention = {"preset_id": preset, "cluster": "neg_low", "solution_id": "neg_low_crisis_01"}
            session_id = await save_to_supabase(payload, profile, g, intervention, debug_log, crisis_scores_llm)
            return {"session_id": session_id, "final_scores": crisis_scores_llm, "g_score": g, "profile": profile, "intervention": intervention, "debug_log": debug_log}
         
        # --- íŒŒì´í”„ë¼ì¸ 4: ì „ì²´ ìŠ¤ì½”ì–´ë§ ë¡œì§ (ëª¨ë“  ì•ˆì „ì¥ì¹˜ í†µê³¼ ì‹œ) ---
        # 4-1. Fusion
        text_if = {c: 0.0 for c in CLUSTERS}
        if llm_json and not llm_json.get("error"):
            I, F = llm_json.get("intensity", {}), llm_json.get("frequency", {})
            for c in CLUSTERS:
                In = clip01((I.get(c, 0.0) or 0.0) / 3.0)
                Fn = clip01((F.get(c, 0.0) or 0.0) / 3.0)
                text_if[c] = clip01(0.6 * In + 0.4 * Fn + 0.1 * rule_scores.get(c, 0.0))
        
        fused_scores = {c: clip01(W_RULE * rule_scores.get(c, 0.0) + W_LLM * text_if.get(c, 0.0)) for c in CLUSTERS}
        debug_log["fused"] = fused_scores
        
        # 4-2. Meta & DSM Calibrate
        meta_scores = meta_adjust(fused_scores, payload)
        final_scores = dsm_calibrate(meta_scores)
        
        # 4-3. Profile, G-Score, Intervention
        g = g_score(final_scores)
        profile = pick_profile(final_scores, llm_json)
        analysis_text = get_analysis_message(final_scores)
        debug_log.update({"g_score": g, "profile": profile, "pca": pca_proxy(final_scores)})

        top_cluster = max(final_scores, key=final_scores.get, default="neg_low")
        solution_info = await get_solution_proposal(top_cluster)
        
        intervention = { "preset_id": "SOLUTION_PROPOSAL", "analysis_text": analysis_text, **solution_info }

        # --- íŒŒì´í”„ë¼ì¸ 5: ìµœì¢… ì €ì¥ ë° ë°˜í™˜ ---
        session_id = await save_to_supabase(payload, profile, g, intervention, debug_log, final_scores)
        return {"session_id": session_id, "final_scores": final_scores, "g_score": g, "profile": profile, "intervention": intervention, "debug_log": debug_log}

    except Exception as e:
        tb = traceback.format_exc()
        print(f"âŒ Checkin Error: {e}\n{tb}")
        return {"error": str(e), "trace": tb}