# main.py
# ì´ê±° ì—”ë“œí¬ì¸íŠ¸ ë¶„ì„/ì†”ë£¨ì…˜ ë‘ê°œë¡œ ë‚˜ëˆˆë²„ì „!!

from __future__ import annotations

import datetime as dt
import json
import os
import re
import traceback
import random
from typing import Optional, List, Dict, Any, Tuple

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.concurrency import run_in_threadpool
from pydantic import BaseModel
from supabase import create_client, Client


from llm_prompts import call_llm, TRIAGE_SYSTEM_PROMPT, ANALYSIS_SYSTEM_PROMPT, FRIENDLY_SYSTEM_PROMPT
from rule_based import rule_scoring
from srj5_constants import (
    CLUSTERS, DSM_BETA, META_WEIGHTS, ONBOARDING_MAPPING,
    W_LLM, W_RULE, SOLUTION_ID_LIBRARY, ANALYSIS_MESSAGE_LIBRARY, SOLUTION_PROPOSAL_SCRIPTS,
    SAFETY_LEMMAS, SAFETY_LEMMA_COMBOS, PCA_PROXY
)

try:
    from kiwipiepy import Kiwi
    _kiwi = Kiwi()
except Exception:
    _kiwi = None

# --- í™˜ê²½ì„¤ì • ---
load_dotenv()
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
# BIND_HOST = os.getenv("BIND_HOST", "0.0.0.0")
# PORT = int(os.getenv("PORT", "8000"))
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")


# Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸
supabase: Optional[Client] = None

# --- FastAPI ì•± ì´ˆê¸°í™” ë° ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
app = FastAPI(title="DailyMoji API v2 (Separated Logic)")

# supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@app.on_event("startup")
def startup_event():
    global supabase
    if SUPABASE_URL and SUPABASE_KEY:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("âœ… FastAPI server started and Supabase client initialized.")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"],
)

# --- ë°ì´í„° ëª¨ë¸ (ë¶„ë¦¬ëœ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •) ---

# /analyze ì—”ë“œí¬ì¸íŠ¸ì˜ ì…ë ¥ ëª¨ë¸
class AnalyzeRequest(BaseModel):
    user_id: str
    text: str
    icon: Optional[str] = None
    timestamp: Optional[str] = None
    onboarding: Optional[Dict[str, Any]] = None


# /solutions/propose ì—”ë“œí¬ì¸íŠ¸ì˜ ì…ë ¥ ëª¨ë¸
class SolutionRequest(BaseModel):
    user_id: str
    session_id: str
    top_cluster: str

# Flutterì˜ PresetIdsì™€ ë™ì¼í•œ êµ¬ì¡°
class PresetIds:
    FRIENDLY_REPLY = "FRIENDLY_REPLY"
    SOLUTION_PROPOSAL = "SOLUTION_PROPOSAL"
    SAFETY_CRISIS_MODAL = "SAFETY_CRISIS_MODAL"
    EMOJI_REACTION = "EMOJI_REACTION"

# ======================================================================
# === kiwië¥¼ ì‚¬ìš©í•˜ëŠ” ì•ˆì „ ì¥ì¹˜ ë° Helper í•¨ìˆ˜ë“¤ ===
# ======================================================================

# --- ì•ˆì „ ì¥ì¹˜ ë¡œì§ ---
SAFETY_REGEX = [r"ì£½ê³ \s*ì‹¶", r"ì‚´ê³ \s*ì‹¶ì§€", r"ì‚´ê¸°\s*ì‹«", r"ìì‚´", r"ë›°ì–´\s*ë‚´ë¦¬", r"íˆ¬ì‹ ", r"ëª©ì„\s*ë§¤ë‹¬", r"ëª©ìˆ¨(?:ì„)?\s*ëŠ", r"ìƒì„\s*ë§ˆê°", r"ì£½ì–´ë²„ë¦¬", r"ëë‚´ë²„ë¦¬"]
SAFETY_FIGURATIVE = [r"ì£½ì„\s*ë§Œí¼", r"ì£½ê² ë‹¤\s*ã…‹", r"ê°œ\s*ë§›ìˆ"]

def _find_regex_matches(text: str, patterns: List[str]) -> List[str]:
    return [m.group(0) for pat in patterns for m in re.finditer(pat, text, flags=re.IGNORECASE)]

def _kiwi_detect_safety_lemmas(text: str) -> List[str]:
    if not _kiwi: return []
    try:
        tokens = _kiwi.tokenize(text)
        all_lemmas_in_text = {t.lemma for t in tokens}
        hits = {token.lemma for token in tokens if token.lemma in SAFETY_LEMMAS}
        for combo in SAFETY_LEMMA_COMBOS:
            if combo.issubset(all_lemmas_in_text):
                hits.update(combo)
        return list(hits)
    except Exception as e:
        print(f"Kiwi safety check error: {e}")
        return []

def is_safety_text(text: str, llm_json: Optional[dict], debug_log: dict) -> Tuple[bool, dict]:
    kiwi_lemma_hits = _kiwi_detect_safety_lemmas(text)
    safety_llm_flag = (llm_json or {}).get("intent", {}).get("self_harm") in {"possible", "likely"}
    
    # ì€ìœ ì ì´ê±°ë‚˜ ë†ë‹´ í‘œí˜„ì´ ì—†ì„ ë•Œë§Œ ì•ˆì „ ì¥ì¹˜ë¥¼ ë°œë™
    is_figurative = bool(_find_regex_matches(text, SAFETY_FIGURATIVE))
    triggered = (bool(kiwi_lemma_hits) or safety_llm_flag) and not is_figurative
    
    debug_log["safety"] = {
        "regex_matches": _find_regex_matches(text, SAFETY_REGEX),
        "figurative_matches": _find_regex_matches(text, SAFETY_FIGURATIVE),
        "kiwi_lemma_hits": kiwi_lemma_hits,
        "llm_intent_flag": safety_llm_flag,
        "triggered": triggered
    }
    
    if triggered:
        # ì•ˆì „ ì¥ì¹˜ê°€ ë°œë™í•˜ë©´, neg_low ì ìˆ˜ë¥¼ ê·¹ë‹¨ì ìœ¼ë¡œ ë†’ì—¬ ìœ„ê¸° ìƒí™©ì„ì„ ëª…ì‹œ
        return True, {"neg_low": 0.95, "neg_high": 0.0, "adhd_high": 0.0, "sleep": 0.0, "positive": 0.0}
    
    return False, {}


# --- Helper í•¨ìˆ˜ë“¤ ---
def clip01(x: float) -> float: return max(0.0, min(1.0, float(x)))

# def _is_night(ts: Optional[str]) -> bool:
#     try:
#         if not ts: return False
#         hour = dt.datetime.fromisoformat(ts.replace("Z", "+00:00")).hour
#         return hour >= 22 or hour < 7
#     except Exception: return False

def g_score(final_scores: dict) -> float:
    w = {"neg_high": 1.0, "neg_low": 0.9, "sleep": 0.7, "adhd_high": 0.6, "positive": -0.3}
    g = sum(final_scores.get(k, 0.0) * w.get(k, 0.0) for k in CLUSTERS)
    return round(clip01((g + 1.0) / 2.0), 3)

def calculate_baseline_scores(onboarding_scores: Optional[Dict[str, int]]) -> Dict[str, float]:
    if not onboarding_scores: return {c: 0.0 for c in CLUSTERS}
    baseline = {c: 0.0 for c in CLUSTERS}
    for q_key, score in onboarding_scores.items():
        processed_score = 3 - score if q_key == 'q7' else score
        if q_key in ONBOARDING_MAPPING:
            normalized_score = processed_score / 3.0
            for mapping in ONBOARDING_MAPPING[q_key]:
                baseline[mapping["cluster"]] += normalized_score * mapping["w"]
    for c in CLUSTERS:
        baseline[c] = clip01(baseline.get(c, 0.0))
    return baseline


def meta_adjust(base_scores: dict, payload: AnalyzeRequest) -> dict:
    s = base_scores.copy()

    # ì´ëª¨ì§€ ì•„ì´ì½˜ ì ìˆ˜ ê°€ì¤‘ì¹˜ 
    if payload.icon:
        # ì´ëª¨ì§€ ì„ íƒ ì‹œ 70%, ì˜¨ë³´ë”© 30%ë¥¼ ë°±ì—”ë“œì—ì„œ ê²°í•©
        # ì—¬ê¸°ì„œ base_scoresëŠ” ì´ë¯¸ LLMê³¼ Rule ê¸°ë°˜ ì ìˆ˜ê°€ ìœµí•©ëœ ìƒíƒœ.
        # ê¸°ì¡´ ì ìˆ˜(LLM+Rule)ì— ì´ëª¨ì§€ ì ìˆ˜ë¥¼ 'ì¶”ê°€'í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹Œ,
        # 'ì¬ê³„ì‚°' ë˜ëŠ” 'ê°•ë ¥í•œ ë³´ì •' ê°œë…ìœ¼ë¡œ ì ‘ê·¼.
        # -> ë°±ì—”ë“œì—ì„œ icon íŒŒë¼ë¯¸í„°ê°€ ë“¤ì–´ì™”ì„ ë•Œ, í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬.

        # í´ëŸ¬ìŠ¤í„° ë§¤í•‘ 
        icon_to_cluster = {
            "angry": "neg_high",
            "crying": "neg_low",
            "shocked": "adhd_high",
            "sleeping": "sleep",
            "smile": "positive",
        }
        
        selected_cluster = icon_to_cluster.get(payload.icon.lower())
        if selected_cluster:
            s[selected_cluster] = clip01(s.get(selected_cluster, 0.0) + META_WEIGHTS["icon"])
    return s           
            



# def dsm_calibrate(scores: dict) -> dict:
#     # í˜„ì¬ëŠ” survey ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ë¹„í™œì„±í™”
#     return scores

def pick_profile(final_scores: dict, llm: dict | None) -> int: # surveys íŒŒë¼ë¯¸í„° ì œê±°
    if (llm or {}).get("intent", {}).get("self_harm") in {"possible", "likely"}: return 1
    if max(final_scores.get("neg_low", 0), final_scores.get("neg_high", 0)) > 0.85: return 1
    # if (surveys and (surveys.get("phq9", 0) >= 10 or surveys.get("gad7", 0) >= 10)) or max(final_scores.values()) > 0.60: return 2
    if max(final_scores.values()) > 0.60: return 2 # surveys í•„ë“œ ì œê±°
    if max(final_scores.values()) > 0.30: return 3
    return 0

# def pca_proxy(final_scores: dict) -> dict:
#     pc1 = sum(final_scores.get(k, 0.0) * w for k, w in PCA_PROXY["pc1"].items())
#     pc2 = sum(final_scores.get(k, 0.0) * w for k, w in PCA_PROXY["pc2"].items())
#     return {"pc1": round(max(-1.0, min(1.0, pc1)), 3), "pc2": round(clip01((pc2 + 1.0) / 2.0), 3)}

# def generate_friendly_reply(text: str) -> str:
#     llm_response = call_llm(system_prompt=FRIENDLY_SYSTEM_PROMPT, user_content=text, openai_key=OPENAI_KEY, model="gpt-4o-mini", temperature=0.7, expect_json=False)
#     return str(llm_response).strip()


# ìˆ˜ì¹˜ë¥¼ ì£¼ê¸°ë³´ë‹¤ëŠ”, ì‹¬ê°ë„ 3ë‹¨ê³„ì— ë”°ë¼ ë©”ì‹œì§€ í•´ì„í•´ì£¼ëŠ”ê²Œ ë‹¬ë¼ì§(ìˆ˜ì¹˜í˜•x, ëŒ€í™”í˜•o)
def get_analysis_message(scores: dict) -> str:
    if not scores: return "ë‹¹ì‹ ì˜ ë§ˆìŒì„ ë” ë“¤ì—¬ë‹¤ë³´ê³  ìˆì–´ìš”."
    top_cluster = max(scores, key=scores.get)
    score_val = scores[top_cluster]
    
    level = "low"
    if score_val > 0.7: level = "high"
    elif score_val > 0.4: level = "mid"
    
    return ANALYSIS_MESSAGE_LIBRARY.get(top_cluster, {}).get(level, "ì˜¤ëŠ˜ ë‹¹ì‹ ì˜ ë§ˆìŒì€ íŠ¹ë³„í•œ ìƒ‰ì„ ë ê³  ìˆë„¤ìš”.")


# def get_solution_proposal(top_cluster: str) -> Dict[str, Any]:
#     # 1. ë©˜íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ëœë¤ìœ¼ë¡œ ë©˜íŠ¸ í•˜ë‚˜ ì„ íƒ
#     proposal_script = random.choice(SOLUTION_PROPOSAL_SCRIPTS.get(top_cluster, [""]))
#     # 2. ì†”ë£¨ì…˜ ID ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ëœë¤ìœ¼ë¡œ ID í•˜ë‚˜ ì„ íƒ
#     solution_id = random.choice(SOLUTION_ID_LIBRARY.get(top_cluster, [None]))
    
#     if not solution_id:
#         return {"proposal_text": "ì§€ê¸ˆì€ ì œì•ˆí•´ë“œë¦´ë§Œí•œ íŠ¹ë³„í•œ í™œë™ì´ ì—†ë„¤ìš”. ëŒ€ì‹ , í¸ì•ˆí•˜ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆê¹Œìš”?", "solution_id": None, "solution_data": None}

#     solution_data = None
#     if supabase and solution_id:
#         try:
#             # TODO: ë‚˜ì¤‘ì— ë¹„ë™ê¸°ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œí•˜ê¸°
#             response = supabase.table("solutions").select("*").eq("solution_id", solution_id).maybe_single().execute()
#             solution_data = response.data
#         except Exception as e:
#             print(f"Supabase solution fetch error: {e}")

#     final_text = proposal_script
#     if solution_data and solution_data.get('text'):
#         final_text += solution_data.get('text')
        
#     return {"proposal_text": final_text, "solution_id": solution_id, "solution_data": solution_data}


async def save_analysis_to_supabase(payload: AnalyzeRequest, profile: int, g: float,
                              intervention: dict, debug_log: dict,
                              final_scores: dict) -> Optional[str]:
    if not supabase: 
        return None
    try:
        session_row = {
            "user_id": payload.user_id, "text": payload.text, "profile": profile,
            "g_score": g, "intervention": json.dumps(intervention, ensure_ascii=False),
            "debug_log": json.dumps(debug_log, ensure_ascii=False), "icon": payload.icon,
        }
        response = await run_in_threadpool(supabase.table("sessions").insert(session_row).execute)
        new_session_id = response.data[0]['id']

        if final_scores:
            score_rows = [
                {"session_id": new_session_id, "user_id": payload.user_id,
                 "cluster": c, "score": v}
                for c, v in final_scores.items()
            ]
            if score_rows:
                await run_in_threadpool(supabase.table("cluster_scores").insert(score_rows).execute)

        return new_session_id
    except Exception as e:
        print(f"Supabase ì €ì¥ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None


# ---------- API Endpoints (ë¶„ë¦¬ëœ êµ¬ì¡°) ----------

# ======================================================================
# ===          ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸         ===
# ======================================================================
 
@app.post("/analyze")
async def analyze_emotion(payload: AnalyzeRequest):
    """ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸ì™€ ì•„ì´ì½˜ì„ ë°›ì•„ ê°ì •ì„ ë¶„ì„í•˜ê³  ìŠ¤ì½”ì–´ë§ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    text = (payload.text or "").strip()
    debug_log: Dict[str, Any] = {"input": payload.dict()}
    try:
        # --- UX Flow 1: EMOJI_ONLY -> ê³µê°/ì§ˆë¬¸ìœ¼ë¡œ ì‘ë‹µ (0924 ìŠ¬ë™ë…¼ì˜ 2ë²ˆ ë¡œì§)---
        if payload.icon and not text:
            debug_log["mode"] = "EMOJI_REACTION"
            # Supabaseì—ì„œ í•´ë‹¹ ì´ëª¨ì§€ í‚¤ë¥¼ ê°€ì§„ ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ëª¨ë‘ ê°€ì ¸ì˜´
            response = await run_in_threadpool(
                supabase.table("reaction_scripts").select("script").eq("emotion_key", payload.icon.lower()).execute
            )
            
            scripts = [row['script'] for row in response.data]
            
            # ë§Œì•½ ìŠ¤í¬ë¦½íŠ¸ê°€ ìˆë‹¤ë©´ ê·¸ ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒ, ì—†ë‹¤ë©´ ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©
            reaction_text = random.choice(scripts) if scripts else "ì§€ê¸ˆ ê¸°ë¶„ì´ ì–´ë– ì‹ ì§€ ì•Œë ¤ì£¼ì„¸ìš”."

            intervention = {"preset_id": PresetIds.EMOJI_REACTION, "text": reaction_text}
            session_id = await save_analysis_to_supabase(payload, 0, 0.5, intervention, debug_log, {})
            
            return {"session_id": session_id, "intervention": intervention}



        # --- í…ìŠ¤íŠ¸ ì…ë ¥ ì¼€ì´ìŠ¤ ---

        # --- íŒŒì´í”„ë¼ì¸ 1: 1ì°¨ ì•ˆì „ ì¥ì¹˜ (LLM ì—†ì´) ---
        is_safe, safety_scores = is_safety_text(text, None, debug_log)
        if is_safe:
            print(f"ğŸš¨ 1ì°¨ ì•ˆì „ ì¥ì¹˜ ë°œë™: '{text}'")
            profile, g = 1, g_score(safety_scores)
            top_cluster = "neg_low"
            intervention = {"preset_id": PresetIds.SAFETY_CRISIS_MODAL, "analysis_text": "ë§ì´ í˜ë“œì‹œêµ°ìš”. ì§€ê¸ˆ ë„ì›€ì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.", "solution_id": f"{top_cluster}_crisis_01", "cluster": top_cluster}
            session_id = await save_analysis_to_supabase(payload, profile, g, intervention, debug_log, safety_scores)
            return {"session_id": session_id, "intervention": intervention}

        # --- íŒŒì´í”„ë¼ì¸ 2: Triage (ì¹œêµ¬ ëª¨ë“œ / ë¶„ì„ ëª¨ë“œ ë¶„ê¸°) ---
        rule_scores, _, _ = rule_scoring(text)
        if max(rule_scores.values() or [0.0]) < 0.3 and len(text) < 15:
            debug_log["mode"] = "FRIENDLY"
            friendly_text = await call_llm(FRIENDLY_SYSTEM_PROMPT, text, OPENAI_KEY, expect_json=False)
            intervention = {"preset_id": PresetIds.FRIENDLY_REPLY, "text": friendly_text}
            # ì¹œê·¼í•œ ëŒ€í™”ë„ ì„¸ì…˜ì„ ë‚¨ê¸¸ ìˆ˜ ìˆìŒ (ìŠ¤ì½”ì–´ëŠ” ë¹„ì–´ìˆìŒ)
            session_id = await save_analysis_to_supabase(payload, 0, 0.5, intervention, debug_log, {})
            return {"session_id": session_id, "intervention": intervention}

        # --- íŒŒì´í”„ë¼ì¸ 3: ë¶„ì„ ëª¨ë“œ ---
        debug_log["mode"] = "ANALYSIS"
        llm_payload = payload.dict()
        llm_payload["baseline_scores"] = calculate_baseline_scores(payload.onboarding or {})
        llm_json = await call_llm(ANALYSIS_SYSTEM_PROMPT, json.dumps(llm_payload, ensure_ascii=False), OPENAI_KEY)
        debug_log["llm"] = llm_json
        
        # --- íŒŒì´í”„ë¼ì¸ 3.5: 2ì°¨ ì•ˆì „ ì¥ì¹˜ (LLM ê²°ê³¼ ê¸°ë°˜) ---
        is_safe_llm, crisis_scores_llm = is_safety_text(text, llm_json, debug_log)
        if is_safe_llm:
            profile, g = 1, g_score(crisis_scores_llm)
            top_cluster = "neg_low"
            intervention = {
                "preset_id": PresetIds.SAFETY_CRISIS_MODAL,
                "analysis_text": "ë§ì´ í˜ë“œì‹œêµ°ìš”. ì§€ê¸ˆ ë„ì›€ì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.",
                "solution_id": f"{top_cluster}_crisis_01",
                "cluster": top_cluster
            }
            session_id = await save_analysis_to_supabase(payload, profile, g, intervention, debug_log, crisis_scores_llm)
            return {"session_id": session_id, "intervention": intervention}


        # === ì•ˆì „ì¥ì¹˜ ëª¨ë‘ í†µê³¼ ì‹œ ===
        # --- íŒŒì´í”„ë¼ì¸ 4: ì „ì²´ ìŠ¤ì½”ì–´ë§ ë¡œì§ ---
        # 4-1. Fusion 
        text_if = {c: 0.0 for c in CLUSTERS}
        if llm_json and not llm_json.get("error"):
            I, F = llm_json.get("intensity", {}), llm_json.get("frequency", {})
            for c in CLUSTERS:
                In = clip01((I.get(c, 0.0) or 0.0) / 3.0)
                Fn = clip01((F.get(c, 0.0) or 0.0) / 3.0)
                text_if[c] = clip01(0.6 * In + 0.4 * Fn + 0.1 * rule_scores.get(c, 0.0))
        
        fused_scores = {c: clip01(W_RULE * rule_scores.get(c, 0.0) + W_LLM * text_if.get(c, 0.0)) for c in CLUSTERS}
        
        # 4-2. Meta Adjust
        adjusted_scores = meta_adjust(fused_scores, payload)
        debug_log["scores"] = {"llm_detail": text_if, "rule": rule_scores, "fused": fused_scores, "final": adjusted_scores}
        
        # 4-3. ìµœì¢… ê²°ê³¼ ìƒì„± 
        g = g_score(adjusted_scores)
        profile = pick_profile(adjusted_scores, llm_json)
        top_cluster = max(adjusted_scores, key=adjusted_scores.get, default="neg_low")
        
        # LLMìœ¼ë¡œë¶€í„° ê³µê° ë©”ì‹œì§€ì™€ ë¶„ì„ ë©”ì‹œì§€ë¥¼ ê°ê° ê°€ì ¸ì˜´
        empathy_text = (llm_json or {}).get("empathy_response", "ë§ˆìŒì„ ì‚´í”¼ëŠ” ì¤‘ì´ì—ìš”...")
        analysis_text = get_analysis_message(adjusted_scores)
    
        
        
        # 4-4. Intervention ê°ì²´ ìƒì„± ë° ë°˜í™˜ (API ì‘ë‹µ êµ¬ì¡° ìˆ˜ì •í•¨)
        intervention = {
            "preset_id": PresetIds.SOLUTION_PROPOSAL,
            "empathy_text": empathy_text, # ê³µê° í…ìŠ¤íŠ¸ ì¶”ê°€
            "analysis_text": analysis_text,
            "top_cluster": top_cluster
        }
        
        session_id = await save_analysis_to_supabase(payload, profile, g, intervention, debug_log, adjusted_scores)
        
        return {
            "session_id": session_id,
            "final_scores": adjusted_scores,
            "g_score": g,
            "profile": profile,
            "intervention": intervention 
        }

    except Exception as e:
        tb = traceback.format_exc()
        raise HTTPException(status_code=500, detail={"error": str(e), "trace": tb})


# ======================================================================
# ===          ì†”ë£¨ì…˜ ì—”ë“œí¬ì¸íŠ¸         ===
# ======================================================================
   

@app.post("/solutions/propose")
async def propose_solution(payload: SolutionRequest): 
    """ë¶„ì„ ê²°ê³¼(top_cluster)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë§ëŠ” ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ëŠ” ë¡œì§"""
    if not supabase:
        raise HTTPException(status_code=500, detail="Supabase client not initialized")
        
    try:
        # 1. ì œì•ˆ ë©˜íŠ¸ì™€ ì†”ë£¨ì…˜ IDë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒ
        proposal_script = random.choice(SOLUTION_PROPOSAL_SCRIPTS.get(payload.top_cluster, [""]))
        solution_id = random.choice(SOLUTION_ID_LIBRARY.get(payload.top_cluster, [None]))
        
        # 2. ì†”ë£¨ì…˜ IDê°€ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ì˜ˆì™¸ ì²˜ë¦¬ 
        if not solution_id:
            return {
                "proposal_text": "ì§€ê¸ˆì€ ì œì•ˆí•´ë“œë¦´ë§Œí•œ íŠ¹ë³„í•œ í™œë™ì´ ì—†ë„¤ìš”. ëŒ€ì‹ , í¸ì•ˆí•˜ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆê¹Œìš”?", 
                "solution_id": None,
                "solution_details": None
            }
        
        # 3. Supabaseì—ì„œ ì†”ë£¨ì…˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        # ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì•ˆì „í•˜ê²Œ ì‹¤í–‰
        response = await run_in_threadpool(
            supabase.table("solutions").select("text, url, startAt, endAt").eq("solution_id", solution_id).maybe_single().execute
        )
        solution_data = response.data


        
        # 4. ìµœì¢… ì œì•ˆ í…ìŠ¤íŠ¸ ì¡°í•© ë° ë¡œê·¸ ì €ì¥
        final_text = proposal_script + (solution_data.get('text') if solution_data and solution_data.get('text') else "")
        # ë¡œê·¸ ì €ì¥ ì—­ì‹œ ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ run_in_threadpool ì‚¬ìš©
        await run_in_threadpool(
            supabase.table("interventions_log").insert({"session_id": payload.session_id, "type": "propose", "solution_id": solution_id}).execute
        )
        
        return {
            "proposal_text": final_text, 
            "solution_id": solution_id, 
            "solution_details": solution_data
        }
  
    except Exception as e:
        tb = traceback.format_exc()
        print(f"âŒ Propose Solution Error: {e}\n{tb}")
        raise HTTPException(status_code=500, detail={"error": str(e), "trace": tb})
