from __future__ import annotations

import datetime as dt
import json
import os
import re
import traceback
from typing import Optional, List, Dict, Any, Union

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from supabase import create_client

# LLM í˜¸ì¶œ í•¨ìˆ˜ì™€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ë¦¬í•´ì„œ ê´€ë¦¬í•˜ê¸° í¸í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
from llm_prompts import (
    call_llm,
    ANALYSIS_SYSTEM_PROMPT,
    FRIENDLY_SYSTEM_PROMPT
)

# í˜•íƒœì†Œ ë¶„ì„: ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ graceful fallback
try:
    from kiwipiepy import Kiwi
    _kiwi = Kiwi()
except Exception:
    _kiwi = None

from rule_based import rule_scoring
from srj5_constants import (
    CLUSTERS, DSM_BETA, DSM_WEIGHTS, INTERVENTIONS,
    META_WEIGHTS, PCA_PROXY, RULE_SKIP_LLM,
    SAFETY_TERMS, SEVERITY_LOW_MAX, SEVERITY_MED_MAX,
    W_LLM, W_RULE
)

# ---------- í™˜ê²½ì„¤ì • ----------
load_dotenv()
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

# Docker í™˜ê²½ì—ì„œëŠ” '0.0.0.0'ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤ê³  í•¨.
BIND_HOST = os.getenv("BIND_HOST", "0.0.0.0") 
# BIND_HOST = os.getenv("BIND_HOST", "127.0.0.1")
PORT = int(os.getenv("PORT", "8000"))

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")  # ì„œë¹„ìŠ¤ í‚¤ ì‚¬ìš©
supabase = None
if SUPABASE_URL and SUPABASE_KEY:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# ---------- FastAPI ----------
app = FastAPI(title="DailyMoji API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------- ë°ì´í„° ëª¨ë¸ ----------
class Checkin(BaseModel):
    text: str
    icon: Optional[str] = None
    intensity: Optional[float] = None
    contexts: Optional[List[str]] = None
    timestamp: Optional[str] = None
    surveys: Optional[Dict[str, Any]] = None
    onboarding: Optional[Dict[str, Any]] = None


# ---------- Safety: Regex + Kiwi + LLM intent ê²°í•© ----------
# 1) ìì‚´ ì•”ì‹œ/ì˜ì‚¬ í‘œí˜„ ì •ê·œì‹(ë‹¤ì–‘í•œ ë³€í˜• í¬í•¨)
SAFETY_REGEX = [
    r"ì£½ê³ \s*ì‹¶(?:ë‹¤|ì–´|ë‹¤\.)",              # ì£½ê³ ì‹¶ë‹¤/ì£½ê³  ì‹¶ì–´
    r"ì‚´ê³ \s*ì‹¶ì§€\s*ì•Š(?:ë‹¤|ì•„)",           # ì‚´ê³  ì‹¶ì§€ ì•Šë‹¤
    r"ìì‚´\s*(?:í•˜ê³ \s*ì‹¶|ì¶©ë™|ìƒê°)",       # ìì‚´ í•˜ê³  ì‹¶/ì¶©ë™/ìƒê°
    r"ëª©ìˆ¨(?:ì„)?\s*(?:ëŠ|ë²„ë¦¬|í¬ê¸°)\s*í•˜ê³ ?\s*ì‹¶(?:ë‹¤|ì–´)?",
    r"ìƒì„\s*ë§ˆê°í•˜(?:ê³ |ê³ \s*ì‹¶|ê³ ì‹¶)",
    r"ì£½ì–´ë²„ë¦¬(?:ê³ )?\s*ì‹¶(?:ë‹¤|ì–´)?",
    r"ëë‚´ë²„ë¦¬(?:ê³ )?\s*ì‹¶(?:ë‹¤|ì–´)?",
    r"ì‚´ê¸°\s*ì‹«(?:ë‹¤|ì–´)",
]

# 2) ê±°ì§“ì–‘ì„±(ë¹„ìœ /ë†ë‹´/ê¸ì •ë¬¸ë§¥) í•„í„°
SAFETY_FIGURATIVE = [
    r"ì£½ì„\s*ë§Œí¼\s*(?:ë§›ìˆ|ì¬ë°Œ|ì›ƒê¸°|í–‰ë³µ|ì¢‹)",
    r"ì£½ê² ë‹¤\s*ã…‹ã…‹",
    r"ê°œ\s*ë§›ìˆ",   # ë¬¸ë§¥ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ ê¸°ë³¸ ì°¨ë‹¨
]

def _find_regex_matches(text: str, patterns: List[str]) -> List[str]:
    hits = []
    for pat in patterns:
        for m in re.finditer(pat, text, flags=re.IGNORECASE):
            hits.append(m.group(0))
    return hits

def _kiwi_tokens(text: str) -> List[str]:
    if not _kiwi:
        return []
    try:
        return [t.form for t in _kiwi.tokenize(text)]
    except Exception:
        return []

def _kiwi_has_selfharm_combo(text: str) -> bool:
    """
    ì£½/VV + ê³  + ì‹¶/VX ì¡°í•©, ì‚´/VV + ê³  + ì‹¶ + ì§€ ì•Š ì¡°í•© ë“± í˜•íƒœì†Œ ê¸°ë°˜ íƒì§€
    """
    if not _kiwi:
        return False
    try:
        tokens = _kiwi.tokenize(text)
        lemmas = [f"{t.tag}:{t.form}" for t in tokens]  # ë””ë²„ê¹…ìš©
        # ë‹¨ìˆœ íŒ¨í„´: 'ì£½' ë™ì‚¬ + 'ì‹¶' ë³´ì¡°/í˜•íƒœ, í˜¹ì€ 'ì‚´' + 'ì‹¶' + 'ì•Š'
        forms = [t.form for t in tokens]
        tags = [t.tag for t in tokens]

        # ì£½-ê³ -ì‹¶
        for i in range(len(forms) - 2):
            if ("ì£½" in forms[i] or "ì£½" in forms[i].rstrip("ë‹¤")) and \
               (forms[i+1] in ["ê³ ", "ê³ ìš”"]) and \
               ("ì‹¶" in forms[i+2] or "ì‹¶" in forms[i+2].rstrip("ë‹¤")):
                return True

        # ì‚´-ê³ -ì‹¶-ì§€-ì•Š
        for i in range(len(forms) - 4):
            if ("ì‚´" in forms[i] or "ì‚´" in forms[i].rstrip("ë‹¤")) and \
               (forms[i+1] in ["ê³ ", "ê³ ìš”"]) and \
               ("ì‹¶" in forms[i+2]) and \
               (forms[i+3] in ["ì§€"]) and \
               ("ì•Š" in forms[i+4] or "ì•„ë‹ˆ" in forms[i+4]):
                return True

        return False
    except Exception:
        return False

def is_safety_text(text: str, llm_json: dict | None, debug_log: dict) -> bool:
    # 1) ì •ê·œì‹ íƒì§€
    regex_hits = _find_regex_matches(text, SAFETY_REGEX)
    figurative_hits = _find_regex_matches(text, SAFETY_FIGURATIVE)

    # 2) Kiwi í˜•íƒœì†Œ ì¡°í•©(ì˜µì…˜)
    kiwi_combo = _kiwi_has_selfharm_combo(text)
    kiwi_tokens = _kiwi_tokens(text)

    # 3) LLM intent
    safety_llm_flag = (llm_json or {}).get("intent", {}).get("self_harm") in {"possible", "likely"}

    # 4) ìµœì¢… íŒì •: (ì •ê·œì‹ or kiwi ì¡°í•© or LLM) AND (ë¹„ìœ /ë†ë‹´ íŒ¨í„´ì´ ì—†ìŒ)
    triggered = (bool(regex_hits) or kiwi_combo or safety_llm_flag) and not bool(figurative_hits)

    # --- ë¡œê·¸ ë‚¨ê¸°ê¸° ---
    debug_log["safety"] = {
        "regex_matches": regex_hits,
        "figurative_matches": figurative_hits,
        "kiwi_combo": kiwi_combo,
        "kiwi_tokens": kiwi_tokens[:50],  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ
        "llm_intent_flag": safety_llm_flag,
        "triggered": triggered,
    }
    return triggered


# ---------- Helpers ----------
def clip01(x: float) -> float: return float(max(0.0, min(1.0, x)))

def severity_level(s: float) -> str:
    if s <= SEVERITY_LOW_MAX: return "low"
    if s <= SEVERITY_MED_MAX: return "medium"
    return "high"

def meta_adjust(base_scores: dict, payload: Checkin) -> dict:
    s = base_scores.copy()
    if payload.icon and payload.icon.lower() in CLUSTERS:
        s[payload.icon.lower()] = clip01(s[payload.icon.lower()] + META_WEIGHTS["icon"] * 0.2)
    if payload.intensity is not None:
        inten = clip01(payload.intensity / 10.0)
        for c in ["neg_low","neg_high","sleep","adhd_high"]:
            s[c] = clip01(s[c] + inten * META_WEIGHTS["intensity_self"] * 0.2)
    ctxs = [c.lower() for c in (payload.contexts or [])]
    if "night" in ctxs or _is_night(payload.timestamp):
        s["sleep"] = clip01(s["sleep"] + META_WEIGHTS["time"] * 0.2)
    return s

def _is_night(ts: Optional[str]) -> bool:
    try:
        if not ts: return False
        hour = dt.datetime.fromisoformat(ts.replace("Z","+00:00")).hour
        return hour >= 22 or hour < 7
    except Exception: return False

def dsm_calibrate(scores: dict, surveys: dict | None) -> dict:
    s = {}
    for c, v in scores.items():
        v = v * DSM_WEIGHTS.get(c, 1.0)
        if surveys:
            z = 0.0
            if c == "neg_low" and "phq9" in surveys: z = (surveys["phq9"] - 10) / 10.0
            if c == "neg_high" and "gad7" in surveys: z = (surveys["gad7"] - 10) / 10.0
            if c == "sleep" and "psqi" in surveys: z = (surveys["psqi"] - 10) / 10.0
            if c == "adhd_high" and "asrs" in surveys: z = (surveys["asrs"] - 12) / 8.0
            if c == "positive" and "rses" in surveys: z = (surveys["rses"] - 20) / 10.0
            v = clip01(v + DSM_BETA.get(c,0.1)*z)
        s[c] = clip01(v)
    return s

def pca_proxy(final_scores: dict) -> dict:
    pc1 = sum(final_scores.get(k,0.0) * w for k,w in PCA_PROXY["pc1"].items())
    pc2 = sum(final_scores.get(k,0.0) * w for k,w in PCA_PROXY["pc2"].items())
    return {"pc1": round(max(-1.0,min(1.0,pc1)),3),
            "pc2": round(clip01((pc2+1.0)/2.0),3)}

def pick_profile(final_scores: dict, llm: dict, surveys: dict | None) -> int:
    intent = (llm or {}).get("intent",{})
    if intent.get("self_harm") in {"possible","likely"}: return 1
    return (
        1 if max(final_scores.get("neg_low",0),final_scores.get("neg_high",0)) > 0.85 else
        2 if (surveys and ((surveys.get("phq9",0)>=10) or (surveys.get("gad7",0)>=10))) or
             max(final_scores.values()) > 0.60 else
        3 if max(final_scores.values()) > 0.30 else
        0
    )

def map_intervention(profile: int, final_scores: dict, is_night: bool, llm: dict|None) -> dict:
    top = max(final_scores.items(), key=lambda x:x[1])[0]
    sev = severity_level(final_scores[top])
    sleep_evidence = (llm or {}).get("evidence_spans",{}).get("sleep",[])
    if is_night and top=="neg_low" and sev in {"high","medium"} and sleep_evidence:
        top="sleep"; sev="medium" if sev=="high" else sev
    candidates=[r for r in INTERVENTIONS if r["cluster"]==top and (r["severity"] in {sev,"any"})]
    if not candidates: candidates=[r for r in INTERVENTIONS if r["cluster"]==top]
    if not candidates: candidates=[r for r in INTERVENTIONS]
    return sorted(candidates,key=lambda r:r["priority"],reverse=True)[0]

def g_score(final_scores: dict) -> float:
    w={"neg_high":1.0,"neg_low":0.9,"sleep":0.7,"adhd_high":0.6,"positive":-0.3}
    g=sum(final_scores.get(k,0.0)*w.get(k,0.0) for k in CLUSTERS)
    return round(clip01((g+1.0)/2.0),3)

# ---------- "ì¹œêµ¬ ëª¨ë“œ" ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ----------
async def generate_friendly_reply(text: str) -> str:
    # ì¹œêµ¬ í˜ë¥´ì†Œë‚˜ë¥¼ ê°€ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    llm_response = await call_llm(
        system_prompt=FRIENDLY_SYSTEM_PROMPT,
        user_content=text,
        openai_key=OPENAI_KEY, # ì—¬ê¸°ì„œ í‚¤ì „ë‹¬
        model="gpt-4o-mini",
        temperature=0.7 # ì•½ê°„ì˜ ì°½ì˜ì„±ì„ ë¶€ì—¬
    )
    # LLM ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (JSONì´ ì•„ë‹˜)
    try:
        # ì‘ë‹µì´ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if isinstance(llm_response, dict) and "choices" in llm_response:
             return llm_response["choices"][0]["message"]["content"].strip()
        return str(llm_response).strip() # ë§Œì•½ì˜ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë¬¸ìì—´ë¡œ ë³€í™˜
    except Exception:
        return "ìŒ... ë°©ê¸ˆ ë­ë¼ê³  í•˜ì…¨ì£ ? ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”? ğŸ¤”"


# ---------- API ----------
@app.post("/checkin")
async def checkin(payload: Checkin):
    text = (payload.text or "").strip()
    debug_log: Dict[str, Any] = {}


    try:
 # --- 1ë‹¨ê³„: ì•ˆì „ ì¥ì¹˜ ìµœìš°ì„  ê²€ì‚¬ ---
        # (LLM ì—†ì´, ì •ê·œì‹ê³¼ Kiwi ë¶„ì„ë§Œìœ¼ë¡œ 1ì°¨ ê²€ì‚¬)
        if is_safety_text(text, None, debug_log):
            print(f"ğŸš¨ ì•ˆì „ ëª¨ë“œ ì‹¤í–‰: '{text}'")
            debug_log["mode"] = "SAFETY_CRISIS"
            return {
                "session_id": None, "input": payload.dict(), "final_scores": {}, "g_score": 1.0, "profile": 1,
                "intervention": {
                    "preset_id": "SAFETY_CRISIS_MODAL",
                    "text": "ë§ì´ í˜ë“  ë§ˆìŒì´ ëŠê»´ì ¸ìš”. í˜¼ì ë™ë™ ì•“ì§€ ë§ê³ , ì´ì•¼ê¸°í•  ê³³ì´ í•„ìš”í•˜ë‹¤ë©´ ê¼­ ì—°ë½í•´ë³´ì„¸ìš”."
                },
                "debug_log": debug_log,
            }

        # --- 2ë‹¨ê³„: ëª¨ë“œ ê²°ì • (ì¹œêµ¬ ëª¨ë“œ or ë¶„ì„ ëª¨ë“œ) ---
        rule_scores, _, _ = rule_scoring(text)
        max_rule_score = max(rule_scores.values() or [0.0])
        # (ê°ì • ì ìˆ˜ê°€ 0.1ë³´ë‹¤ í¬ê±°ë‚˜) AND (ê¸€ì ê¸¸ì´ê°€ 4ë³´ë‹¤ í¬ë©´) -> ë¶„ì„ ëª¨ë“œ
        is_emotional_text = max_rule_score > 0.1 and len(text) > 4 

        if not is_emotional_text:
            # --- 3-A. "ì¹œêµ¬ ëª¨ë“œ"ë¡œ ì‘ë™ ---
            debug_log["mode"] = "FRIENDLY_REPLY"
            print(f"ğŸ’¬ ì¹œêµ¬ ëª¨ë“œ ì‹¤í–‰: '{text}'")
            friendly_text = await generate_friendly_reply(text)
            return {
                "session_id": None, "input": payload.dict(), "final_scores": {}, "g_score": 0.0, "profile": 0,
                "intervention": {"preset_id": "FRIENDLY_REPLY", "text": friendly_text},
                "debug_log": debug_log,
            }
        
        # --- 3-B. "ì½”ì¹˜(ë¶„ì„) ëª¨ë“œ"ë¡œ ì‘ë™ ---
        debug_log["mode"] = "ANALYSIS"
        print(f"âœ¨ ë¶„ì„ ëª¨ë“œ ì‹¤í–‰: '{text}'")
        
        # ê¸°ì¡´ì˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘
        # 1) Rule
        rule_scores, rule_evidence, debug_log_rule = rule_scoring(text)
        rule_max = max(rule_scores.values() or [0.0])
        debug_log["rule_scores"] = rule_scores
        debug_log["rule_evidence"] = rule_evidence
        debug_log["rule_debug"] = debug_log_rule  # ê°•ì¡°ì–´/ìŠ¬ë­ ê¸°ë¡ -- ì—¬ê¸°ì„œ ignored í† í° í™•ì¸ ê°€ëŠ¥

        # 2) LLM
        # ìˆ˜ì •ëœ ì½”ë“œ
        llm_json = await call_llm(
            system_prompt=ANALYSIS_SYSTEM_PROMPT, 
            user_content=json.dumps(payload.dict(), ensure_ascii=False),
            openai_key=OPENAI_KEY, # ì—¬ê¸°ì„œ í‚¤ì „ë‹¬
        )
        debug_log["llm"] = llm_json

        # 3) Fusion
        text_if={c:0.0 for c in CLUSTERS}
        if llm_json and not llm_json.get("error"):
            I,F=llm_json.get("intensity",{}),llm_json.get("frequency",{})
            for c in CLUSTERS:
                In=clip01((I.get(c,0.0) or 0.0)/3.0)
                Fn=clip01((F.get(c,0.0) or 0.0)/3.0)
                b_lex=0.1*rule_scores.get(c,0.0)
                text_if[c]=clip01(0.6*In+0.4*Fn+b_lex)
        fused={c:clip01(W_RULE*rule_scores.get(c,0.0)+W_LLM*text_if.get(c,0.0)) for c in CLUSTERS}
        debug_log["fused"]=fused

        # 4) Meta + DSM
        meta_adj=meta_adjust(fused,payload); debug_log["meta"]=meta_adj
        cal=dsm_calibrate(meta_adj,payload.surveys); debug_log["calibrated"]=cal
        final_scores=cal; debug_log["final_scores"]=final_scores

        # 5) PCA / Profile / Intervention
        pca=pca_proxy(final_scores); debug_log["pca"]=pca
        profile=pick_profile(final_scores,llm_json,payload.surveys); debug_log["profile"]=profile
        intervention=map_intervention(profile,final_scores,_is_night(payload.timestamp),llm_json)
        debug_log["intervention"]=intervention

        # 6) Safety (ê°•í™” ë²„ì „: Regex/Ko-morph + LLM intent ê²°í•©)
        if is_safety_text(text, llm_json, debug_log):
            profile = 1
            intervention = {
                "cluster": "neg_low",
                "severity": "high",
                "preset_id": "safety_crisis_modal_v1",
                "priority": 1000,
                "safety_check": True,
            }
            debug_log["safety_override_applied"] = True

        # 7) G-score
        g=g_score(final_scores); debug_log["g_score"]=g

        # ---------- Supabase ì €ì¥ ----------
        new_session_id = None
        if supabase:
            try:
                session_row={
                    "created_at":dt.datetime.utcnow().isoformat(),
                    "text":text,
                    "profile":profile,
                    "g_score":g,
                    "intervention":json.dumps(intervention),
                    "debug_log":json.dumps(debug_log, ensure_ascii=False),
                }
                response = supabase.table("sessions").insert(session_row).execute()
                new_session_id = response.data[0]['id']

                if final_scores: # final_scoresê°€ ìˆì„ ë•Œë§Œ cluster_scores ì €ì¥
                    for c,v in final_scores.items():
                        supabase.table("cluster_scores").insert({
                            "created_at":dt.datetime.utcnow().isoformat(),
                            "cluster":c,"score":v,"session_text":text[:100],
                            "user_id": payload.user_id 
                        }).execute()
            except Exception as e:
                print("Supabase ì €ì¥ ì‹¤íŒ¨:",e)

        # --- ìµœì¢… ì‘ë‹µ ---
        return {
            "input": payload.dict(),
            "final_scores": final_scores,
            "g_score": g,
            "profile": profile,
            "intervention": intervention,
            "debug_log": debug_log,
        }

    except Exception as e:
        tb = traceback.format_exc()
        print("âŒ Checkin Error:", e)
        print(tb)
        return {"error": str(e), "trace": tb}

# ì´ ë¶€ë¶„ì€ Dockerfileì˜ CMDê°€ ì²˜ë¦¬í•˜ë¯€ë¡œ ì‚­ì œ ê°€ëŠ¥.
# if __name__=="__main__":
#     import uvicorn
#     uvicorn.run(app,host=BIND_HOST,port=PORT,reload=True)
