# main.py
from __future__ import annotations

import datetime as dt
import json
import os
import re
import traceback
import random
from typing import Optional, List, Dict, Any, Tuple
import uuid

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.concurrency import run_in_threadpool
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from supabase import create_client, Client


from llm_prompts import call_llm, get_system_prompt, TRIAGE_SYSTEM_PROMPT, FRIENDLY_SYSTEM_PROMPT 
from rule_based import rule_scoring
from srj5_constants import (
    CLUSTERS, EMOJI_ONLY_SCORE_CAP, ICON_TO_CLUSTER, ONBOARDING_MAPPING,
    FINAL_FUSION_WEIGHTS, FINAL_FUSION_WEIGHTS_NO_TEXT,
    W_LLM, W_RULE, 
    SAFETY_LEMMAS, SAFETY_LEMMA_COMBOS, SAFETY_REGEX, SAFETY_FIGURATIVE
)


try:
    from kiwipiepy import Kiwi
    _kiwi = Kiwi()
except Exception:
    _kiwi = None

# --- í™˜ê²½ì„¤ì • ---
load_dotenv()
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
# BIND_HOST = os.getenv("BIND_HOST", "0.0.0.0")
# PORT = int(os.getenv("PORT", "8000"))
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")


# Supabase í´ë¼ì´ì–¸íŠ¸ë¥¼ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸
supabase: Optional[Client] = None

# --- FastAPI ì•± ì´ˆê¸°í™” ë° ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ---
app = FastAPI(title="DailyMoji API v2 (Separated Logic)")

# supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
@app.on_event("startup")
def startup_event():
    global supabase
    if SUPABASE_URL and SUPABASE_KEY:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("âœ… FastAPI server started and Supabase client initialized.")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"],
)

# --- ë°ì´í„° ëª¨ë¸ (ë¶„ë¦¬ëœ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •) ---

# /analyze ì—”ë“œí¬ì¸íŠ¸ì˜ ì…ë ¥ ëª¨ë¸
class AnalyzeRequest(BaseModel):
    user_id: str
    text: str
    icon: Optional[str] = None
    language_code: Optional[str] = 'ko'
    timestamp: Optional[str] = None
    onboarding: Optional[Dict[str, Any]] = None
    character_personality: Optional[str] = None


# /solutions/propose ì—”ë“œí¬ì¸íŠ¸ì˜ ì…ë ¥ ëª¨ë¸
class SolutionRequest(BaseModel):
    user_id: str
    session_id: str
    top_cluster: str
    language_code: Optional[str] = 'ko'


# Flutterì˜ PresetIdsì™€ ë™ì¼í•œ êµ¬ì¡°
class PresetIds:
    FRIENDLY_REPLY = "FRIENDLY_REPLY"
    SOLUTION_PROPOSAL = "SOLUTION_PROPOSAL"
    SAFETY_CRISIS_MODAL = "SAFETY_CRISIS_MODAL"
    EMOJI_REACTION = "EMOJI_REACTION"

# ======================================================================
# === kiwië¥¼ ì‚¬ìš©í•˜ëŠ” ì•ˆì „ ì¥ì¹˜ ===
# ======================================================================

# --- ì•ˆì „ ì¥ì¹˜ ë¡œì§ ---

def _find_regex_matches(text: str, patterns: List[str]) -> List[str]:
    return [m.group(0) for pat in patterns for m in re.finditer(pat, text, flags=re.IGNORECASE)]

def _kiwi_detect_safety_lemmas(text: str) -> List[str]:
    if not _kiwi: return []
    try:
        tokens = _kiwi.tokenize(text)
        all_lemmas_in_text = {t.lemma for t in tokens}
        hits = {token.lemma for token in tokens if token.lemma in SAFETY_LEMMAS}
        for combo in SAFETY_LEMMA_COMBOS:
            if combo.issubset(all_lemmas_in_text):
                hits.update(combo)
        return list(hits)
    except Exception as e:
        print(f"Kiwi safety check error: {e}")
        return []

def is_safety_text(text: str, llm_json: Optional[dict], debug_log: dict) -> Tuple[bool, dict]:
    kiwi_lemma_hits = _kiwi_detect_safety_lemmas(text)
    safety_llm_flag = (llm_json or {}).get("intent", {}).get("self_harm") in {"possible", "likely"}
    
    # ì€ìœ ì ì´ê±°ë‚˜ ë†ë‹´ í‘œí˜„ì´ ì—†ì„ ë•Œë§Œ ì•ˆì „ ì¥ì¹˜ë¥¼ ë°œë™
    is_figurative = bool(_find_regex_matches(text, SAFETY_FIGURATIVE))
    triggered = (bool(kiwi_lemma_hits) or safety_llm_flag) and not is_figurative
    
    debug_log["safety"] = {
        "regex_matches": _find_regex_matches(text, SAFETY_REGEX),
        "figurative_matches": _find_regex_matches(text, SAFETY_FIGURATIVE),
        "kiwi_lemma_hits": kiwi_lemma_hits,
        "llm_intent_flag": safety_llm_flag,
        "triggered": triggered
    }
    
    if triggered:
        # ì•ˆì „ ì¥ì¹˜ê°€ ë°œë™í•˜ë©´, neg_low ì ìˆ˜ë¥¼ ê·¹ë‹¨ì ìœ¼ë¡œ ë†’ì—¬ ìœ„ê¸° ìƒí™©ì„ì„ ëª…ì‹œ
        return True, {"neg_low": 0.95, "neg_high": 0.0, "adhd": 0.0, "sleep": 0.0, "positive": 0.0}
    
    return False, {}


# ======================================================================
# === í—¬í¼í•¨ìˆ˜ë“¤ ===
# ======================================================================
# DEBUG LOG: ë³´ê¸° í¸í•œ ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜ ì¶”ê°€
def _format_scores_for_print(scores: dict) -> str:
    """ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ë¥¼ ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ ì˜ˆì˜ê²Œ ì¶œë ¥í•˜ê¸° ìœ„í•œ í•¨ìˆ˜"""
    if not isinstance(scores, dict):
        return str(scores)
    return json.dumps({k: round(v, 2) if isinstance(v, float) else v for k, v in scores.items()}, indent=2)

def clip01(x: float) -> float: return max(0.0, min(1.0, float(x)))

def g_score(final_scores: dict) -> float:
    w = {"neg_high": 1.0, "neg_low": 0.9, "sleep": 0.7, "adhd": 0.6, "positive": -0.3}
    g = sum(final_scores.get(k, 0.0) * w.get(k, 0.0) for k in CLUSTERS)
    return round(clip01((g + 1.0) / 2.0), 3)

def calculate_baseline_scores(onboarding_scores: Optional[Dict[str, int]]) -> Dict[str, float]:
    if not onboarding_scores: return {c: 0.0 for c in CLUSTERS}
    baseline = {c: 0.0 for c in CLUSTERS}
    for q_key, score in onboarding_scores.items():
        processed_score = 3 - score if q_key == 'q7' else score
        if q_key in ONBOARDING_MAPPING:
            normalized_score = processed_score / 3.0
            for mapping in ONBOARDING_MAPPING[q_key]:
                baseline[mapping["cluster"]] += normalized_score * mapping["w"]
    for c in CLUSTERS:
        baseline[c] = clip01(baseline.get(c, 0.0))
    return baseline


def pick_profile(final_scores: dict, llm: dict | None) -> int: # surveys íŒŒë¼ë¯¸í„° ì œê±°
    if (llm or {}).get("intent", {}).get("self_harm") in {"possible", "likely"}: return 1
    if max(final_scores.get("neg_low", 0), final_scores.get("neg_high", 0)) > 0.85: return 1
    # if (surveys and (surveys.get("phq9", 0) >= 10 or surveys.get("gad7", 0) >= 10)) or max(final_scores.values()) > 0.60: return 2
    if max(final_scores.values()) > 0.60: return 2 # surveys í•„ë“œ ì œê±°
    if max(final_scores.values()) > 0.30: return 3
    return 0


# ğŸ‘€ ëª¨ë“  ë©˜íŠ¸ ì¡°íšŒë¥¼ í†µí•© ê´€ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ í—¬í¼ í•¨ìˆ˜
async def get_mention_from_db(
    mention_type: str,
    personality: Optional[str],
    language_code: str,
    cluster: str,
    level: Optional[str] = None,
    default_message: str = "...",
    format_kwargs: Optional[Dict] = None
) -> str:
    if not supabase: return default_message
    try:
        query = supabase.table("character_mentions").select("text")
        query = query.eq("mention_type", mention_type)
        query = query.eq("language_code", language_code)
        
        if personality: query = query.eq("personality", personality)
        if cluster: query = query.eq("cluster", cluster)
        if level: query = query.eq("level", level)
        
        response = await run_in_threadpool(query.execute)
        scripts = [row['text'] for row in response.data]
        
        if not scripts: return default_message
        
        selected_script = random.choice(scripts)

        if format_kwargs:
            for key, value in format_kwargs.items():
                selected_script = selected_script.replace(f"{{{key}}}", str(value))
        
        return selected_script
    except Exception as e:
        print(f"âŒ get_mention_from_db Error: {e}")
        return default_message


# ìˆ˜ì¹˜ë¥¼ ì£¼ê¸°ë³´ë‹¤ëŠ”, ì‹¬ê°ë„ 3ë‹¨ê³„ì— ë”°ë¼ ë©”ì‹œì§€ í•´ì„í•´ì£¼ëŠ”ê²Œ ë‹¬ë¼ì§(ìˆ˜ì¹˜í˜•x, ëŒ€í™”í˜•o)
async def get_analysis_message(
    scores: dict, 
    personality: Optional[str], 
    language_code: str
) -> str:
    if not scores: return "ë‹¹ì‹ ì˜ ë§ˆìŒì„ ë” ë“¤ì—¬ë‹¤ë³´ê³  ìˆì–´ìš”."
    top_cluster = max(scores, key=scores.get)
    score_val = scores[top_cluster]
    
    level = "low"
    if score_val > 0.7: level = "high"
    elif score_val > 0.4: level = "mid"
    
    return await get_mention_from_db(
        mention_type="analysis",
        personality=personality,
        language_code=language_code,
        cluster=top_cluster,
        level=level,
        default_message="ì˜¤ëŠ˜ ë‹¹ì‹ ì˜ ë§ˆìŒì€ íŠ¹ë³„í•œ ìƒ‰ì„ ë ê³  ìˆë„¤ìš”.",
        format_kwargs={"emotion": top_cluster, "score": int(score_val * 100)}
    )
    


async def save_analysis_to_supabase(
        payload: AnalyzeRequest, profile: int, g: float,
        intervention: dict, debug_log: dict,
        final_scores: dict) -> Optional[str]:
    if not supabase: 
        print("RIN: ğŸš¨ Supabase client not initialized.")
        return None
    try:
        user_id = payload.user_id
        
        # ì„¸ì…˜ì„ ì €ì¥í•˜ê¸° ì „, user_profilesì— í•´ë‹¹ ìœ ì €ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ìƒì„±
        profile_response = await run_in_threadpool(
            supabase.table("user_profiles").select("id").eq("id", user_id).execute
        )
        if not profile_response.data:
            print(f"RIN: âš ï¸ [Backend] User profile for {user_id} not found. Creating one.")
            await run_in_threadpool(
                supabase.table("user_profiles").insert({"id": user_id, "user_nick_nm": "New User"}).execute
            )

        session_row = {
            "user_id": payload.user_id,
            "text": payload.text,
            "profile": int(profile), # profileì€ ì •ìˆ˜(1,2,3)
            "g_score": float(g), # g_scoreì€ float
            "intervention": json.dumps(intervention, ensure_ascii=False),
            "debug_log": json.dumps(debug_log, ensure_ascii=False),
            "icon": payload.icon,
         }
        print(f"RIN: âœ… Saving session to Supabase for user: {payload.user_id}")

        response = await run_in_threadpool(
                    supabase.table("sessions").insert(session_row).execute
                )        
        
        if not response.data or not response.data[0].get('id'):
            print("RIN: ğŸš¨ ERROR: Failed to insert session, no data returned.")
            return None
        
        # new_session_id = response.data[0]['id']
        # ì—¬ê¸°ì„œ ì˜¤ë¥˜ë‚˜ì„œ ê³„ì† ë©ˆì¶˜ë“¯? .get()ë¥¼ ì‚¬ìš©í•˜ì—¬ idì— ì¢€ë” ì•ˆì „í•˜ê²Œ ì ‘ê·¼í•˜ê¸°!
        new_session_id = response.data[0].get('id')


        if not new_session_id:
            print("RIN: ğŸš¨ ERROR: Session ID is null in the returned data.")
            return None
                
        print(f"RIN: âœ… Session saved successfully. session_id: {new_session_id}")


        if final_scores:
            score_rows = [{"session_id": new_session_id, "user_id": user_id, "cluster": c, "score": v} for c, v in final_scores.items()]
            if score_rows:
                await run_in_threadpool(supabase.table("cluster_scores").insert(score_rows).execute)

        return new_session_id
    
    except Exception as e:
        print(f"RIN: ğŸš¨ Supabase ì €ì¥ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None


# ---------- API Endpoints (ë¶„ë¦¬ëœ êµ¬ì¡°) ----------

# ======================================================================
# ===          ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸         ===
# ======================================================================
 
@app.post("/analyze")
async def analyze_emotion(payload: AnalyzeRequest):
    """ì‚¬ìš©ìì˜ í…ìŠ¤íŠ¸ì™€ ì•„ì´ì½˜ì„ ë°›ì•„ ê°ì •ì„ ë¶„ì„í•˜ê³  ìŠ¤ì½”ì–´ë§ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    text = (payload.text or "").strip()
    debug_log: Dict[str, Any] = {"input": payload.dict()}

    # ğŸ¤© RIN: ì‚¬ìš©ì ë‹‰ë„¤ì„ê³¼ ìºë¦­í„° ì´ë¦„ì„ ë¯¸ë¦¬ ì¡°íšŒí•´ë‘¡ë‹ˆë‹¤.
    user_nick_nm = "ì‚¬ìš©ì"
    character_nm = "ëª¨ì§€"
    try:
        if supabase:
            user_profile_res = await run_in_threadpool(
                supabase.table("user_profiles")
                .select("user_nick_nm, character_nm")
                .eq("id", payload.user_id)
                .single()
                .execute
            )
            if user_profile_res.data:
                user_nick_nm = user_profile_res.data.get("user_nick_nm", user_nick_nm)
                character_nm = user_profile_res.data.get("character_nm", character_nm)
    except Exception:
        pass # ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©

    try:
        # RIN ğŸŒ¸ CASE 2 - ì´ëª¨ì§€ë§Œ ì…ë ¥ëœ ê²½ìš°
        if payload.icon and not text:
            debug_log["mode"] = "EMOJI_REACTION"
            top_cluster = ICON_TO_CLUSTER.get(payload.icon.lower(), "neg_low")

            if top_cluster == "neutral": 
            # RIN â™¥ : ë””í´íŠ¸ ì´ëª¨ì§€ëŠ” ë¶„ì„í•˜ì§€ ì•ŠìŒ 
            #  uiì—ì„œ ë§‰ì•„ë†“ê¸´ í• ê±´ë°, í˜¹ì‹œ ëª¨ë¥´ë‹ˆê¹Œ ì¼ë‹¨ êµ¬í˜„ 
                intervention = {
                    "preset_id": PresetIds.EMOJI_REACTION, 
                    "text": "ì˜¤ëŠ˜ì€ ê¸°ë¶„ì´ ì–´ë– ì‹ ê°€ìš”?",
                    "top_cluster": "neutral"
                }
                session_id = await save_analysis_to_supabase(
                    payload, profile=0, g=0.5,
                    intervention=intervention,
                    debug_log=debug_log,
                    final_scores={}
                )
                if session_id:
                    intervention['session_id'] = session_id
                return {
                    "session_id": session_id,
                    "final_scores": {},  
                    "g_score": 0.5,
                    "profile": 0,
                    "intervention": intervention
                }
            pass
            print("\n--- ğŸ§ EMOJI-ONLY ANALYSIS DEBUG ğŸ§ ---")


            # 1. ì˜¨ë³´ë”© ì ìˆ˜ ê³„ì‚°
            onboarding_scores = calculate_baseline_scores(payload.onboarding or {})  
            print(f"Onboarding Scores: {_format_scores_for_print(onboarding_scores)}")

            # 2. ì´ëª¨ì§€ ì ìˆ˜ ìƒì„±
            icon_prior = {c: 0.0 for c in CLUSTERS}
            selected_cluster = ICON_TO_CLUSTER.get(payload.icon.lower())
            if selected_cluster in icon_prior:
                icon_prior[selected_cluster] = 1.0

            # 3. ì˜¨ë³´ë”© 0.2 + ì´ëª¨ì§€ 0.8 ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ 1ì°¨ ìœµí•©
            w = FINAL_FUSION_WEIGHTS_NO_TEXT
            final_scores = {c: clip01(
                onboarding_scores.get(c, 0.0) * w['onboarding'] +
                icon_prior.get(c, 0.0) * w['icon']
            ) for c in CLUSTERS}
            print(f"Final Scores (after fusion): {_format_scores_for_print(final_scores)}")

            # 4. ì ìˆ˜ ìƒí•œì„ (Cap) ì ìš© ë¡œì§ 
            # ì˜¨ë³´ë”©+ì´ëª¨ì§€ ì ìˆ˜ëŠ” ìµœëŒ€ 0.5ê°€ ë˜ë„ë¡ 
            capped_scores = final_scores.copy()
            if selected_cluster in capped_scores:
                # original_score ë³€ìˆ˜ë¥¼ capped_scoresì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •í•˜ì—¬ NameError í•´ê²°
                original_score = capped_scores[selected_cluster]
                capped_scores[selected_cluster] = min(original_score, EMOJI_ONLY_SCORE_CAP)
            
                print(f"Score Capping Applied for '{selected_cluster}': {original_score:.4f} -> {capped_scores[selected_cluster]:.4f}")

            # 5. ìµœì¢… ì ìˆ˜(g_score)
            g = g_score(capped_scores)   
            profile = pick_profile(capped_scores, None)


            print(f"Final Scores (after capping): {_format_scores_for_print(capped_scores)}")
            print(f"G-Score: {g:.2f}")
            print(f"Profile: {profile}")
            print("------â¤ï¸-------------â¤ï¸-----------â¤ï¸-------\n")   

            # --- EMOJI_ONLY - DB ì €ì¥ ë° ë°˜í™˜ ë¡œì§---
            # Supabaseì—ì„œ í•´ë‹¹ ì´ëª¨ì§€ í‚¤ë¥¼ ê°€ì§„ ìŠ¤í¬ë¦½íŠ¸ë“¤ì„ ëª¨ë‘ ê°€ì ¸ì˜´
            reaction_text = "ê¸°ë¶„ì„ ì•Œë ¤ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”!"
            # reaction_scripts ëŒ€ì‹  character_mentions ì¡°íšŒ
            reaction_text = await get_mention_from_db(
                mention_type="reaction",
                personality=payload.character_personality,
                language_code=payload.language_code,
                cluster=ICON_TO_CLUSTER.get(payload.icon.lower(), "common"),
                default_message="ì–´ë–¤ ì¼ ë•Œë¬¸ì— ê·¸ë ‡ê²Œ ëŠë¼ì…¨ë‚˜ìš”?",
                format_kwargs={"user_nick_nm": user_nick_nm}
            )

            intervention = {
                "preset_id": PresetIds.EMOJI_REACTION, 
                "empathy_text": reaction_text,
                "top_cluster": top_cluster
            }

            # g_score/score ì €ì¥ì„ baseline+prior ê¸°ë°˜ìœ¼ë¡œ ì €ì¥
            session_id = await save_analysis_to_supabase(
                payload, profile=profile, g=g,
                intervention=intervention,
                debug_log=debug_log,
                final_scores=capped_scores
            )

            if session_id:
                intervention['session_id'] = session_id

            return {
                "session_id": session_id,
                "final_scores": capped_scores,  
                "g_score": g,
                "profile": profile,
                "intervention": intervention
            }
        pass


        # --- í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ëª¨ë“  ê²½ìš° ---


    # <<<<<<<     ì•ˆì „ì¥ì¹˜    >>>>>>>>
        # --- íŒŒì´í”„ë¼ì¸ 1: 1ì°¨ ì•ˆì „ ì¥ì¹˜ (LLM ì—†ì´) ---
        is_safe, safety_scores = is_safety_text(text, None, debug_log)
        if is_safe:
            print(f"ğŸš¨ 1ì°¨ ì•ˆì „ ì¥ì¹˜ ë°œë™: '{text}'")
            profile, g = 1, g_score(safety_scores)
            top_cluster = "neg_low"
            intervention = {"preset_id": PresetIds.SAFETY_CRISIS_MODAL, "analysis_text": "ë§ì´ í˜ë“œì‹œêµ°ìš”. ì§€ê¸ˆ ë„ì›€ì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.", "solution_id": f"{top_cluster}_crisis_01", "cluster": top_cluster}
            session_id = await save_analysis_to_supabase(payload, profile, g, intervention, debug_log, safety_scores)
            return {"session_id": session_id, "intervention": intervention}
        pass

        # --- íŒŒì´í”„ë¼ì¸ 2: Triage (ì¹œêµ¬ ëª¨ë“œ / ë¶„ì„ ëª¨ë“œ ë¶„ê¸°) ---
        # 1ì°¨ í•„í„°: í…ìŠ¤íŠ¸ê°€ ë§¤ìš° ì§§ê³ , ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ê°€ ê±°ì˜ ì—†ëŠ” ê²½ìš° LLM í˜¸ì¶œ ì—†ì´ ë°”ë¡œ 'FRIENDLY'ë¡œ íŒë‹¨
        rule_scores, _, _ = rule_scoring(text)
        
        # ì¡°ê±´: í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ 10ì ë¯¸ë§Œì´ê³ , ëª¨ë“  ê·œì¹™ ê¸°ë°˜ ì ìˆ˜ê°€ 0.1 ë¯¸ë§Œì¼ ë•Œ
        is_simple_text = len(text) < 10 and max(rule_scores.values() or [0.0]) < 0.1

        if is_simple_text:
            triage_mode = 'FRIENDLY'
            debug_log["triage_decision"] = "Rule-based filter: Simple text"
        else:
        # 2ì°¨ íŒë‹¨: 1ì°¨ í•„í„°ë¥¼ í†µê³¼í•œ ê²½ìš°ì—ë§Œ LLMìœ¼ë¡œ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ê°€ ë¶„ì„ì´ í•„ìš”í•œ ë‚´ìš©ì¸ì§€, ë‹¨ìˆœ ëŒ€í™”ì¸ì§€ ë¨¼ì € íŒë‹¨!!
            triage_mode = await call_llm(
                system_prompt=TRIAGE_SYSTEM_PROMPT,
                user_content=text,
                openai_key=OPENAI_KEY,
                expect_json=False # 'ANALYSIS' OR 'FRIENDLY'
            )

            debug_log["triage_mode"] = triage_mode
            # Triage ê²°ê³¼ì— ë”°ë¼ ë¶„ê¸°
            if triage_mode == 'FRIENDLY':
                debug_log["mode"] = "FRIENDLY"
                print(f"\n--- ğŸ‘‹ FRIENDLY MODE DEBUG ---")
                print(f"Input text: '{text}' -> Classified as FRIENDLY")
                print("------â¤ï¸-------------â¤ï¸-----------â¤ï¸-------\n")
            

                # ğŸ¤© RIN: ì¹œêµ¬ ëª¨ë“œì—ì„œë„ ìºë¦­í„° ì„±í–¥ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©í•˜ê¸°
                system_prompt = get_system_prompt(
                    mode='FRIENDLY',
                    personality=payload.character_personality,
                    language_code=payload.language_code,
                    user_nick_nm=user_nick_nm,
                    character_nm=character_nm
                )           
                friendly_text = await call_llm(system_prompt, text, OPENAI_KEY, expect_json=False)

                intervention = {"preset_id": PresetIds.FRIENDLY_REPLY, "text": friendly_text}
                # ì¹œê·¼í•œ ëŒ€í™”ë„ ì„¸ì…˜ì„ ë‚¨ê¸¸ ìˆ˜ ìˆìŒ (ìŠ¤ì½”ì–´ëŠ” ë¹„ì–´ìˆìŒ)
                session_id = await save_analysis_to_supabase(payload, 0, 0.5, intervention, debug_log, {})
                return {"session_id": session_id, "intervention": intervention}

            else: # triage_mode == 'ANALYSIS' ë˜ëŠ” ì˜ˆì™¸ ë°œìƒ ì‹œ ê¸°ë³¸ê°’
                # --- íŒŒì´í”„ë¼ì¸ 3: ë¶„ì„ ëª¨ë“œ ---
                debug_log["mode"] = "ANALYSIS"
                print("\n--- ğŸ§ TEXT ANALYSIS DEBUG ğŸ§ ---")

                # 3-1. ì˜¨ë³´ë”© ì ìˆ˜(Baseline) ê³„ì‚°
                onboarding_scores = calculate_baseline_scores(payload.onboarding or {})
                print(f"1. Onboarding Scores:\n{_format_scores_for_print(onboarding_scores)}")

                # 3-2. í…ìŠ¤íŠ¸ ë¶„ì„ ì ìˆ˜(fused_scores) ê³„ì‚° (LLM, Rule-based í¬í•¨)
                # rule_scores, _, _ = rule_scoring(text)
                # ğŸ¤© RIN: ë¶„ì„ ëª¨ë“œì—ì„œë„ ìºë¦­í„° ì„±í–¥ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©í•˜ê¸°
                system_prompt = get_system_prompt(
                    mode='ANALYSIS',
                    personality=payload.character_personality,
                    language_code=payload.language_code,
                    user_nick_nm=user_nick_nm,
                    character_nm=character_nm
                )      
                llm_payload = payload.dict()
                llm_payload["baseline_scores"] = onboarding_scores
                llm_json = await call_llm(system_prompt, json.dumps(llm_payload, ensure_ascii=False), OPENAI_KEY)
                debug_log["llm"] = llm_json
                
                # --- íŒŒì´í”„ë¼ì¸ 3.5: 2ì°¨ ì•ˆì „ ì¥ì¹˜ (LLM ê²°ê³¼ ê¸°ë°˜) - ì ìˆ˜ ê³„ì‚° ì „ ì‹¤í–‰ ---
                is_safe_llm, crisis_scores_llm = is_safety_text(text, llm_json, debug_log)
                if is_safe_llm:
                    print(f"ğŸš¨ 2ì°¨ ì•ˆì „ ì¥ì¹˜ ë°œë™: '{text}'")
                    # ì•ˆì „ ëª¨ë“œ ë°œë™ ì‹œì—ëŠ” ìœ„ê¸° ì ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  DBì— ì €ì¥
                    profile, g = 1, g_score(crisis_scores_llm)
                    top_cluster = "neg_low"
                    intervention = {
                        "preset_id": PresetIds.SAFETY_CRISIS_MODAL,
                        "analysis_text": "ë§ì´ í˜ë“œì‹œêµ°ìš”. ì§€ê¸ˆ ë„ì›€ì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.",
                        "solution_id": f"{top_cluster}_crisis_01",
                        "cluster": top_cluster
                    }
                    # ì´ ê²½ìš°, ì‹¤ì œ ê³„ì‚°ëœ ì ìˆ˜ê°€ ì•„ë‹Œ ìœ„ê¸° ì ìˆ˜(crisis_scores_llm)ë¥¼ ì €ì¥
                    session_id = await save_analysis_to_supabase(
                        payload, profile=profile, g=g, intervention=intervention,
                        debug_log=debug_log, final_scores=crisis_scores_llm
                    )
                    # ë°˜í™˜ê°’ë„ ìœ„ê¸° ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
                    return {
                        "session_id": session_id,
                        "final_scores": crisis_scores_llm,
                        "g_score": g,
                        "profile": profile,
                        "intervention": intervention
                    }

                # === ì•ˆì „ì¥ì¹˜ ëª¨ë‘ í†µê³¼ ì‹œ ===
                # --- íŒŒì´í”„ë¼ì¸ 4: ì „ì²´ ìŠ¤ì½”ì–´ë§ ë¡œì§ ---
                # 4-1. í…ìŠ¤íŠ¸ ë¶„ì„ ì ìˆ˜(fused_scores) ê³„ì‚° 
                rule_scores, _, _ = rule_scoring(text)
                text_if = {c: 0.0 for c in CLUSTERS}
                if llm_json and not llm_json.get("error"):
                    I, F = llm_json.get("intensity", {}), llm_json.get("frequency", {})
                    for c in CLUSTERS:
                        In = clip01((I.get(c, 0.0) or 0.0) / 3.0)
                        Fn = clip01((F.get(c, 0.0) or 0.0) / 3.0)
                        text_if[c] = clip01(0.6 * In + 0.4 * Fn + 0.1 * rule_scores.get(c, 0.0))
                
                fused_scores = {c: clip01(W_RULE * rule_scores.get(c, 0.0) + W_LLM * text_if.get(c, 0.0)) for c in CLUSTERS}
                print(f"2a. Rule-Based Scores:\n{_format_scores_for_print(rule_scores)}")
                print(f"2b. LLM-based Scores (I/F fusion):\n{_format_scores_for_print(text_if)}")
                print(f"2c. Fused Text Scores (Rule + LLM):\n{_format_scores_for_print(fused_scores)}")

                # 4-2. ì´ëª¨ì§€ ì ìˆ˜(icon_prior) ìƒì„±
                icon_prior = {c: 0.0 for c in CLUSTERS}
                has_icon = payload.icon and ICON_TO_CLUSTER.get(payload.icon.lower()) != "neutral"
                if has_icon:
                    selected_cluster = ICON_TO_CLUSTER.get(payload.icon.lower())
                    icon_prior[selected_cluster] = 1.0        
                print(f"3. Icon Prior Scores:\n{_format_scores_for_print(icon_prior)}")

                
                # --- ê°€ì¤‘ì¹˜ ì¬ì¡°ì • ë¡œì§ ---

                # 4-3. FINAL_FUSION_WEIGHTSë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ì ìˆ˜ ìœµí•© (ê°€ì¤‘ì¹˜ ì¬ì¡°ì • í¬í•¨)
                w = FINAL_FUSION_WEIGHTS

                if not has_icon:
                # RIN ğŸŒ¸ CASE 1: í…ìŠ¤íŠ¸ë§Œ ì…ë ¥ ì‹œ (icon ì—†ìŒ) -> icon ê°€ì¤‘ì¹˜ë¥¼ textì™€ onboardingì— ë¹„ë¡€ ë°°ë¶„
                    w_text = w['text'] + w['icon'] * (w['text'] / (w['text'] + w['onboarding']))
                    w_onboarding = w['onboarding'] + w['icon'] * (w['onboarding'] / (w['text'] + w['onboarding']))
                    w_icon = 0.0
                else:
                # RIN ğŸŒ¸ CASE 3: í…ìŠ¤íŠ¸ + ì´ëª¨ì§€ ì…ë ¥ ì‹œ -> ëª¨ë“  ê°€ì¤‘ì¹˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    w_text, w_onboarding, w_icon = w['text'], w['onboarding'], w['icon']

                weights_used = {"text": w_text, "onboarding": w_onboarding, "icon": w_icon}
                print(f"4. Final Fusion Weights:\n{_format_scores_for_print(weights_used)}")

                adjusted_scores = {c: clip01(
                    fused_scores.get(c, 0.0) * w_text +
                    onboarding_scores.get(c, 0.0) * w_onboarding +
                    icon_prior.get(c, 0.0) * w_icon
                ) for c in CLUSTERS}
                print(f"5. Final Adjusted Scores (after fusion):\n{_format_scores_for_print(adjusted_scores)}")

                debug_log["scores"] = {
                    "weights_used": {"text": w_text, "onboarding": w_onboarding, "icon": w_icon},
                    "1_onboarding_scores": onboarding_scores,
                    "2_text_fused_scores": fused_scores,
                    "3_icon_prior": icon_prior,
                    "4_final_adjusted_scores": adjusted_scores
                }
                
                # 5. ìµœì¢… ê²°ê³¼ ìƒì„±
                g = g_score(adjusted_scores)
                profile = pick_profile(adjusted_scores, llm_json)
                top_cluster = max(adjusted_scores, key=adjusted_scores.get, default="neg_low")
                
                print(f"G-Score: {g:.2f}")
                print(f"Profile: {profile}")
                print("------â¤ï¸-------------â¤ï¸-----------â¤ï¸-------\n")


                debug_log["scores"] = {
                    "weights_used": {"text": w_text, "onboarding": w_onboarding, "icon": w_icon},
                    "final_adjusted_scores": adjusted_scores
                }

                # LLMìœ¼ë¡œë¶€í„° ê³µê° ë©”ì‹œì§€ì™€ ë¶„ì„ ë©”ì‹œì§€ë¥¼ ê°ê° ê°€ì ¸ì˜´
                empathy_text = (llm_json or {}).get("empathy_response", "ë§ˆìŒì„ ì‚´í”¼ëŠ” ì¤‘ì´ì—ìš”...")
                # ğŸ¤© RIN: get_analysis_message í˜¸ì¶œ ì‹œ ìºë¦­í„° ì„±í–¥ì„ ë„˜ê²¨ì£¼ê³  DBì—ì„œ ë§ëŠ” ë©˜íŠ¸ ê°€ì ¸ì˜´
                analysis_text = await get_analysis_message(
                    adjusted_scores, 
                    payload.character_personality,
                    payload.language_code
                )
                                
                
                # 4-4. Intervention ê°ì²´ ìƒì„± ë° ë°˜í™˜ 
                intervention = {
                    "preset_id": PresetIds.SOLUTION_PROPOSAL,
                    "empathy_text": empathy_text, 
                    "analysis_text": analysis_text,
                    "top_cluster": top_cluster
                }
                
                session_id = await save_analysis_to_supabase(
                    payload, profile=profile, g=g, intervention=intervention,
                    debug_log=debug_log, final_scores=adjusted_scores
                )
                
                if session_id:
                    intervention['session_id'] = session_id


                return {
                    "session_id": session_id,
                    "final_scores": adjusted_scores,
                    "g_score": g,
                    "profile": profile,
                    "intervention": intervention 
                }

    except Exception as e:
        tb = traceback.format_exc()
        raise HTTPException(status_code=500, detail={"error": str(e), "trace": tb})
        pass

# ======================================================================
# ===          ì†”ë£¨ì…˜ ì—”ë“œí¬ì¸íŠ¸         ===
# ======================================================================
   

@app.post("/solutions/propose")
async def propose_solution(payload: SolutionRequest): 
    """ë¶„ì„ ê²°ê³¼(top_cluster)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë§ëŠ” ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ëŠ” ë¡œì§"""
    if not supabase: raise HTTPException(status_code=500, detail="Supabase client not initialized")
        
    try:
        user_id = payload.user_id
        session_id = payload.session_id
        top_cluster = payload.top_cluster
        language_code = payload.language_code

        # 1. ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ - 'ìºë¦­í„° ì„±í–¥'ê³¼ 'ë‹‰ë„¤ì„' ê°€ì ¸ì˜´
        user_nick_nm = "ì‚¬ìš©ì"
        personality = None
        try:
            user_profile_res = await run_in_threadpool(
                supabase.table("user_profiles").select("user_nick_nm, character_personality").eq("id", user_id).single().execute
            )
            if user_profile_res.data:
                user_nick_nm = user_profile_res.data.get("user_nick_nm", "ì¹œêµ¬")
                personality = user_profile_res.data.get("character_personality")
        except Exception as e:
            print(f"âš ï¸ User profile fetch failed for {user_id}, using defaults. Error: {e}")


        # 2. ì œì•ˆ ë©˜íŠ¸ì™€ ì†”ë£¨ì…˜ IDë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒ

        # proposal_scripts í…Œì´ë¸”ì—ì„œ ëœë¤ìœ¼ë¡œ ì œì•ˆ ë©˜íŠ¸ ê°€ì ¸ì˜¤ê¸°
        proposal_script = await get_mention_from_db(
            mention_type="propose",
            personality=personality,
            language_code=language_code,
            cluster=top_cluster,
            default_message="ì´ëŸ° í™œë™ì€ ì–´ë– ì„¸ìš”?",
            format_kwargs={"user_nick_nm": user_nick_nm}
        )
            
        # 3. solutions í…Œì´ë¸”ì—ì„œ í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ì†”ë£¨ì…˜ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        solutions_response = await run_in_threadpool(
            supabase.table("solutions").select("solution_id, text, url, start_at, end_at, context").eq("cluster", top_cluster).execute
        )
        available_solutions = solutions_response.data
        
        if not available_solutions:
            return {"proposal_text": "ì§€ê¸ˆì€ ì œì•ˆí•´ë“œë¦´ë§Œí•œ íŠ¹ë³„í•œ í™œë™ì´ ì—†ë„¤ìš”. ëŒ€ì‹ , í¸ì•ˆí•˜ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆê¹Œìš”?", "solution_id": None}        
               
        # 4. ê°€ì ¸ì˜¨ ì†”ë£¨ì…˜ ëª©ë¡ ì¤‘ í•˜ë‚˜ë¥¼ ëœë¤ìœ¼ë¡œ ì„ íƒ
        solution_data = random.choice(available_solutions)
        solution_id = solution_data.get("solution_id")

        # ì†”ë£¨ì…˜ IDê°€ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ì˜ˆì™¸ ì²˜ë¦¬ 
        if not solution_id:
            return {
                "proposal_text": "ì§€ê¸ˆì€ ì œì•ˆí•´ë“œë¦´ë§Œí•œ íŠ¹ë³„í•œ í™œë™ì´ ì—†ë„¤ìš”. ëŒ€ì‹ , í¸ì•ˆí•˜ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°ˆê¹Œìš”?", 
                "solution_id": None,
                "solution_details": None
            }
        
       # 5. ìµœì¢… ì œì•ˆ í…ìŠ¤íŠ¸ë¥¼ ì¡°í•© (ë©˜íŠ¸ + ì†”ë£¨ì…˜ ìì²´ í…ìŠ¤íŠ¸)
        final_text = proposal_script
        if solution_data and solution_data.get('text'):
            # ë©˜íŠ¸ì™€ ì†”ë£¨ì…˜ í…ìŠ¤íŠ¸ ì‚¬ì´ì— ìì—°ìŠ¤ëŸ¬ìš´ ê³µë°± ì¶”ê°€
            final_text = f"{proposal_script} {solution_data['text']}"


        # 4. ì œì•ˆ ì´ë ¥ì„ ë¡œê·¸ë¡œ ì €ì¥
        log_entry = {
            "created_at": dt.datetime.now(dt.timezone.utc).isoformat(),
            "session_id": session_id,
            "user_id": user_id,
            "type": "propose",
            "solution_id": solution_id
        }
        
        try:
            # Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ìˆê³ , ì„ì‹œ IDê°€ ì•„ë‹ ë•Œë§Œ DBì— ì €ì¥ ì‹œë„
            if supabase and not session_id.startswith("temp_"):
                # 3. Supabaseì— ë¡œê·¸ ì‚½ì…
                await run_in_threadpool(
                    supabase.table("interventions_log").insert(log_entry).execute
                )
                print(f"RIN: âœ… Supabaseì— ë¡œê·¸ ì €ì¥ ì„±ê³µ.")
            else:
                # Supabaseê°€ ì—†ê±°ë‚˜ ì„ì‹œ IDì¸ ê²½ìš° íŒŒì¼ì— ê¸°ë¡
                raise Exception("Supabase client not available or temp session ID.")
        except Exception as e:
            # DB ì €ì¥ì— ì‹¤íŒ¨í•˜ë©´ ë¡œì»¬ íŒŒì¼ì— ê¸°ë¡
            print(f"RIN: âš ï¸ Supabase ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨. ë¡œì»¬ íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤. ì´ìœ : {e}")
            with open("interventions_log.txt", "a", encoding="utf-8") as f:
                f.write(json.dumps(log_entry) + "\n")

        
        content = { 
            "proposal_text": final_text, 
            "solution_id": solution_id, 
            "solution_details": solution_data 
        }
        return JSONResponse(content=content)    
    
    except Exception as e:
        tb = traceback.format_exc()
        print(f"âŒ Propose Solution Error: {e}\n{tb}")
        raise HTTPException(status_code=500, detail={"error": str(e), "trace": tb})


# ======================================================================
# ===          í™ˆí™”ë©´ ëŒ€ì‚¬ ì—”ë“œí¬ì¸íŠ¸         ===
# ======================================================================
# ğŸ¤© RIN: í™ˆ ëŒ€ì‚¬ë“¤ì„ ì„±í–¥ë³„ë¡œ ë¶ˆëŸ¬ì˜¤ë„ë¡ ë³€ê²½
@app.get("/dialogue/home")
async def get_home_dialogue(
    personality: Optional[str] = None, 
    user_nick_nm: Optional[str] = "ì¹œêµ¬",
    language_code: Optional[str] = 'ko',
    emotion: Optional[str] = None 
):
    """í™ˆ í™”ë©´ì— í‘œì‹œí•  ëŒ€ì‚¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if emotion:
        # ì´ëª¨ì§€ê°€ ì„ íƒëœ ê²½ìš°: 'reaction' ë©˜íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        mention_type = "reaction"
        cluster = ICON_TO_CLUSTER.get(emotion.lower(), "common")
    else:
        # ì´ëª¨ì§€ê°€ ì—†ëŠ” ì´ˆê¸° ìƒíƒœ: 'home' ë©˜íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        mention_type = "home"
        cluster = "common"

    dialogue_text = await get_mention_from_db(
        mention_type=mention_type,
        personality=personality,
        language_code=language_code,
        cluster=cluster,
        default_message=f"ì•ˆë…•, {user_nick_nm}! ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë•Œ?",
        format_kwargs={"user_nick_nm": user_nick_nm}
    )
    
    return {"dialogue": dialogue_text}
    
# ======================================================================
# ===  ì†”ë£¨ì…˜ ì™„ë£Œ í›„ í›„ì† ì§ˆë¬¸ì„ ìœ„í•œ ì—”ë“œí¬ì¸íŠ¸   ===
# ======================================================================
@app.get("/dialogue/solution-followup")
async def get_solution_followup_dialogue(
    reason: str, # 'user_closed' ë˜ëŠ” 'video_ended'
    personality: Optional[str] = None, 
    user_nick_nm: Optional[str] = "ì¹œêµ¬",
    language_code: Optional[str] = 'ko'
):
    """ì†”ë£¨ì…˜ì´ ëë‚œ í›„ì˜ ìƒí™©(reason)ê³¼ ìºë¦­í„° ì„±í–¥ì— ë§ëŠ” í›„ì† ì§ˆë¬¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # ì´ìœ (reason)ì— ë”°ë¼ DBì—ì„œ ì¡°íšŒí•  mention_typeì„ ê²°ì •í•©ë‹ˆë‹¤.
    if reason == 'user_closed':
        mention_type = "followup_user_closed"
    else: # 'video_ended' ë˜ëŠ” ê¸°íƒ€
        mention_type = "followup_video_ended"

    # get_mention_from_db í—¬í¼ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©˜íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    dialogue_text = await get_mention_from_db(
        mention_type=mention_type,
        personality=personality,
        language_code=language_code,
        cluster="common", 
        default_message="ì–´ë•Œìš”? ì¢€ ì¢‹ì•„ì§„ ê²ƒ ê°™ì•„ìš”?ğŸ˜Š",
        format_kwargs={"user_nick_nm": user_nick_nm}
    )
    
    return {"dialogue": dialogue_text}


# ======================================================================
# ===  ì†”ë£¨ì…˜ ì™„ë£Œ í›„ í›„ì† ì§ˆë¬¸ì„ ìœ„í•œ ì—”ë“œí¬ì¸íŠ¸   ===
# ======================================================================

# ì†”ë£¨ì…˜ ì œì•ˆì„ ê±°ì ˆí–ˆì„ ë•Œì˜ ë©˜íŠ¸ë¥¼ ì„±í–¥ë³„ë¡œ ì£¼ê¸° ìœ„í•´ ì¶”ê°€
@app.get("/dialogue/decline-solution")
async def get_decline_solution_dialogue(
    personality: Optional[str] = None, 
    user_nick_nm: Optional[str] = "ì¹œêµ¬",
    language_code: Optional[str] = 'ko'
):
    """ì†”ë£¨ì…˜ ì œì•ˆì„ ê±°ì ˆí•˜ê³  ëŒ€í™”ë¥¼ ì´ì–´ê°€ê³  ì‹¶ì–´í•  ë•Œì˜ ë°˜ì‘ ë©˜íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    dialogue_text = await get_mention_from_db(
        mention_type="decline_solution",
        personality=personality,
        language_code=language_code,
        cluster="common",
        default_message="ì•Œê² ìŠµë‹ˆë‹¤. ê·¸ëŸ¼ìš”. ì €ì—ê²Œ í¸ì•ˆí•˜ê²Œ í„¸ì–´ë†“ìœ¼ì„¸ìš”. ê·€ ê¸°ìš¸ì—¬ ë“£ê³  ìˆì„ê²Œìš”.",
        format_kwargs={"user_nick_nm": user_nick_nm}
    )
    
    return {"dialogue": dialogue_text}


# ======================================================================
# ===          ì†”ë£¨ì…˜ ì˜ìƒ ì—”ë“œí¬ì¸íŠ¸         ===
# ======================================================================

    # SolutionPageì—ì„œ ì˜ìƒ ë¡œë“œ
    # í•˜ë“œì½”ë”©ëœ SOLUTION_DETAILS_LIBRARYë¥¼ DB ì¡°íšŒë¡œ ëŒ€ì²´í–ˆìŒ!!
@app.get("/solutions/{solution_id}")
async def get_solution_details(solution_id: str):
    print(f"RIN: âœ… ì†”ë£¨ì…˜ ìƒì„¸ ì •ë³´ ìš”ì²­ ë°›ìŒ: {solution_id}")
    
    if not supabase:
        raise HTTPException(status_code=500, detail="Supabase client not initialized")
    
    try:
        # solutions í…Œì´ë¸”ì—ì„œ í•„ìš”í•œ ë°ì´í„°ë¥¼ ì¡°íšŒ
        response = await run_in_threadpool(
            supabase.table("solutions")
            .select("url, start_at, end_at")
            .eq("solution_id", solution_id)
            .single()
            .execute
        )
        
        solution_data = response.data
        
        if not solution_data:
            raise HTTPException(status_code=404, detail="Solution not found")

        # ìœ íŠœë¸Œ ë¶ˆëŸ¬ì˜¬ë•Œ startAt, endAt (camelCase)ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ í‚¤ë¥¼ ë³€í™˜í•´ì¤Œ
        # supabaseëŠ” snake_caseë¡œ ì €ì¥í•´ì•¼ í•œë‹¤ê³  í•¨.
        response_data = {
            'url': solution_data.get('url'),
            'startAt': solution_data.get('start_at'),
            'endAt': solution_data.get('end_at')
        }
        
        print(f"RIN: âœ… ì†”ë£¨ì…˜ ì •ë³´ ë°˜í™˜: {response_data}")
        return response_data
        
    except Exception as e:
        print(f"RIN: âŒ í•´ë‹¹ ì†”ë£¨ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {solution_id}, ì—ëŸ¬: {e}")
        raise HTTPException(status_code=404, detail="Solution not found")
    

# ======================================================================
# ===     ë¦¬í¬íŠ¸ ìš”ì•½ ì—”ë“œí¬ì¸íŠ¸     ===
# ======================================================================




